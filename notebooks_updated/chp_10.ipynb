{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code 10: Probabilistic Programming Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run 2023-12-27 17:34:02.444362\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pymc as pm\n",
    "import pytensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "import datetime\n",
    "print(f\"Last Run {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use(\"arviz-grayscale\")\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "\n",
    "simple_grad = grad(lambda x: x**2)\n",
    "print(simple_grad(4.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_p_val: -6.697315216064453\n",
      "grad: 2.4000000953674316\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "from jax.scipy.stats import norm\n",
    "\n",
    "def model(test_point, observed):\n",
    "    z_pdf = norm.logpdf(test_point, loc=0, scale=5)\n",
    "    x_pdf = norm.logpdf(observed, loc=test_point, scale=1)\n",
    "    logpdf = z_pdf + x_pdf\n",
    "    return logpdf\n",
    "\n",
    "model_grad = grad(model)\n",
    "\n",
    "observed, test_point = 5.0, 2.5 \n",
    "logp_val = model(test_point, observed)\n",
    "grad = model_grad(test_point, observed)\n",
    "print(f\"log_p_val: {logp_val}\")\n",
    "print(f\"grad: {grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(-6.69731498), array([2.4]))\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    z = pm.Normal(\"z\", 0., 5.)\n",
    "    x = pm.Normal(\"x\", mu=z, sigma=1., observed=observed)\n",
    "\n",
    "func = model.logp_dlogp_function()\n",
    "func.set_extra_values({})\n",
    "print(func(np.array([test_point])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.7 ns ± 0.693 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def fraud_detector(fraud_observations, non_fraud_observations, fraud_prior=8, non_fraud_prior=6):\n",
    "    \"\"\"Conjugate Beta Binomial model for fraud detection\"\"\"\n",
    "    expectation = (fraud_prior + fraud_observations) / (\n",
    "        fraud_prior + fraud_observations + non_fraud_prior + non_fraud_observations)\n",
    "    \n",
    "    if expectation > .5:\n",
    "        return {\"suspend_card\":True}\n",
    "\n",
    "%timeit fraud_detector(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPL Driven Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0029150244650281935"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = np.repeat(2, 2)\n",
    "pdf = stats.norm(0, 1).pdf(observed)\n",
    "np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = np.repeat(2, 1000)\n",
    "pdf = stats.norm(0, 1).pdf(observed)\n",
    "np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999996"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05399096651318805, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[0], np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.9189385332046727, -2.9189385332046727, -2918.9385332046736)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logpdf = stats.norm(0, 1).logpdf(observed)\n",
    "np.log(pdf[0]), logpdf[0], logpdf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9189385332046727"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(pdf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original domain: [-1.   -0.25  0.5   1.25  2.  ]\n",
      "Transformed domain: [       -inf -1.09861229  0.          1.09861229         inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11005/2568761612.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  transform = np.log(domain - lower) - np.log(upper - domain)\n"
     ]
    }
   ],
   "source": [
    "lower, upper = -1, 2\n",
    "domain = np.linspace(lower, upper, 5)\n",
    "transform = np.log(domain - lower) - np.log(upper - domain)\n",
    "print(f\"Original domain: {domain}\")\n",
    "print(f\"Transformed domain: {transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x_interval__: x ~ Uniform(-1, 2)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    x = pm.Uniform(\"x\", -1., 2.)\n",
    "    \n",
    "model.values_to_rvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Variable.eval of __logp_nojac>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.varlogp_nojac.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.2538560220859454 -1.0986122886681098\n",
      "-1.6265233750364456 -1.0986122886681098\n"
     ]
    }
   ],
   "source": [
    "print(model.varlogp.eval({\"x_interval__\":-2}),\n",
    "      model.varlogp_nojac.eval({\"x_interval__\":-2}))\n",
    "print(model.varlogp.eval({\"x_interval__\":1}),\n",
    "      model.varlogp_nojac.eval({\"x_interval__\":1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 17:34:10.985938: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-27 17:34:10.985963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-27 17:34:10.986582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-27 17:34:11.611796: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "tfb = tfp.bijectors\n",
    "\n",
    "lognormal0 = tfd.LogNormal(0., 1.)\n",
    "lognormal1 = tfd.TransformedDistribution(tfd.Normal(0., 1.), tfb.Exp())\n",
    "x = lognormal0.sample(100)\n",
    "\n",
    "np.testing.assert_array_equal(lognormal0.log_prob(x), lognormal1.log_prob(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [sd]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='101000' class='' max='101000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [101000/101000 00:19&lt;00:00 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 1_000 tune and 100_000 draw iterations (1_000 + 100_000 draws total) took 20 seconds.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{sd_log__: sd, TensorConstant(TensorType(float64, shape=(20,)), data=array([-0. ... 01521619])): y}\n",
      "Diverging: 0\n"
     ]
    }
   ],
   "source": [
    "y_observed = stats.norm(0, .01).rvs(20)\n",
    "\n",
    "with pm.Model() as model_transform:\n",
    "    sd = pm.HalfNormal(\"sd\", 5)\n",
    "    y = pm.Normal(\"y\", mu=0, sigma=sd, observed=y_observed)\n",
    "    idata_transform = pm.sample(chains=1, draws=100000)\n",
    "\n",
    "print(model_transform.values_to_rvs)\n",
    "print(f\"Diverging: {idata_transform.sample_stats['diverging'].sum().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [sd]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='101000' class='' max='101000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [101000/101000 00:20&lt;00:00 Sampling chain 0, 41 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 1_000 tune and 100_000 draw iterations (1_000 + 100_000 draws total) took 21 seconds.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{sd: sd, TensorConstant(TensorType(float64, shape=(20,)), data=array([-0. ... 01521619])): y}\n",
      "Diverging: 41\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model_no_transform:\n",
    "    sd = pm.HalfNormal(\"sd\", 5, transform=None)\n",
    "    y = pm.Normal(\"y\", mu=0, sigma=sd, observed=y_observed)\n",
    "    idata_no_transform = pm.sample(chains=1, draws=100000)\n",
    "\n",
    "print(model_no_transform.values_to_rvs)\n",
    "print(f\"Diverging: {idata_no_transform.sample_stats['diverging'].sum().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation Graphs and Automatic Reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 3\n",
    "y = 1\n",
    "x * y / x + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytensor.config.compute_test_value = 'ignore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add [id A]\n",
      " ├─ Mul [id B]\n",
      " │  ├─ x [id C]\n",
      " │  └─ True_div [id D]\n",
      " │     ├─ y [id E]\n",
      " │     └─ x [id C]\n",
      " └─ ExpandDims{axis=0} [id F]\n",
      "    └─ 0 [id G]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fbeb34f3a30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pytensor.tensor.vector(\"x\")\n",
    "y = pytensor.tensor.vector(\"y\")\n",
    "out = x*(y/x) + 0\n",
    "pytensor.printing.debugprint(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepCopyOp [id A] 0\n",
      " └─ y [id B]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fbeb34f3a30>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgraph = pytensor.function([x,y], [out])\n",
    "pytensor.printing.debugprint(fgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3.])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgraph([1],[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 10.1 and Figure 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file is available at img/chp10/symbolic_graph_unopt.png\n",
      "The output file is available at img/chp10/symbolic_graph_opt.png\n"
     ]
    }
   ],
   "source": [
    "pytensor.printing.pydotprint(\n",
    "    out, outfile=\"img/chp10/symbolic_graph_unopt.png\",\n",
    "    var_with_name_simple=False, high_contrast=False, with_ids=True)\n",
    "pytensor.printing.pydotprint(\n",
    "    fgraph, \n",
    "    outfile=\"img/chp10/symbolic_graph_opt.png\", \n",
    "    var_with_name_simple=False, high_contrast=False, with_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum{axes=None} [id A] '__logp'\n",
      " └─ MakeVector{dtype='float64'} [id B]\n",
      "    └─ Sum{axes=None} [id C]\n",
      "       └─ Check{sigma > 0} [id D] 'x_logprob'\n",
      "          ├─ Sub [id E]\n",
      "          │  ├─ Sub [id F]\n",
      "          │  │  ├─ Mul [id G]\n",
      "          │  │  │  ├─ -0.5 [id H]\n",
      "          │  │  │  └─ Pow [id I]\n",
      "          │  │  │     ├─ True_div [id J]\n",
      "          │  │  │     │  ├─ Sub [id K]\n",
      "          │  │  │     │  │  ├─ x [id L]\n",
      "          │  │  │     │  │  └─ 0.0 [id M]\n",
      "          │  │  │     │  └─ 1.0 [id N]\n",
      "          │  │  │     └─ 2 [id O]\n",
      "          │  │  └─ Log [id P]\n",
      "          │  │     └─ Sqrt [id Q]\n",
      "          │  │        └─ 6.283185307179586 [id R]\n",
      "          │  └─ Log [id S]\n",
      "          │     └─ 1.0 [id N]\n",
      "          └─ All{axes=None} [id T]\n",
      "             └─ MakeVector{dtype='bool'} [id U]\n",
      "                └─ All{axes=None} [id V]\n",
      "                   └─ Gt [id W]\n",
      "                      ├─ 1.0 [id N]\n",
      "                      └─ 0 [id X]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fbeb34f3a30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pm.Model() as model_normal:\n",
    "    x = pm.Normal(\"x\", 0., 1.)\n",
    "    \n",
    "pytensor.printing.debugprint(model_normal.logp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpyro\n",
    "from tensorflow_probability.substrates import jax as tfp_jax\n",
    "\n",
    "tfp_dist = tfp_jax.distributions\n",
    "numpyro_dist = numpyro.distributions\n",
    "\n",
    "root = tfp_dist.JointDistributionCoroutine.Root\n",
    "def tfp_model():\n",
    "    x = yield root(tfp_dist.Normal(loc=1.0, scale=2.0, name=\"x\"))\n",
    "    z = yield root(tfp_dist.HalfNormal(scale=1., name=\"z\"))\n",
    "    y = yield tfp_dist.Normal(loc=x, scale=z, name=\"y\")\n",
    "    \n",
    "def numpyro_model():\n",
    "    x = numpyro.sample(\"x\", numpyro_dist.Normal(loc=1.0, scale=2.0))\n",
    "    z = numpyro.sample(\"z\", numpyro_dist.HalfNormal(scale=1.0))\n",
    "    y = numpyro.sample(\"y\", numpyro_dist.Normal(loc=x, scale=z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object tfp_model at 0x7fbd6eb7ee40>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(tfp_model())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(numpyro_model())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = jax.random.PRNGKey(52346)\n",
    "\n",
    "# Draw samples\n",
    "jd = tfp_dist.JointDistributionCoroutine(tfp_model)\n",
    "tfp_sample = jd.sample(1, seed=sample_key)\n",
    "\n",
    "predictive = numpyro.infer.Predictive(numpyro_model, num_samples=1)\n",
    "numpyro_sample = predictive(sample_key)\n",
    "\n",
    "# Evaluate log prob\n",
    "log_likelihood_tfp = jd.log_prob(tfp_sample)\n",
    "log_likelihood_numpyro = numpyro.infer.util.log_density(\n",
    "    numpyro_model, [], {},\n",
    "    # Samples returning from JointDistributionCoroutine is a\n",
    "    # Namedtuple like Python object, we convert it to a dictionary\n",
    "    # so that numpyro can recognize it.\n",
    "    params=tfp_sample._asdict())\n",
    "\n",
    "# Validate that we get the same log prob\n",
    "np.testing.assert_allclose(log_likelihood_tfp, log_likelihood_numpyro[0], rtol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  x=Array(0.4250738, dtype=float32),\n",
       "  z=Array(0.01, dtype=float32),\n",
       "  y=Array(0.42213488, dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condition z to .01 in TFP and sample\n",
    "jd.sample(z=.01, seed=sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': Array([1.1232406], dtype=float32),\n",
       " 'y': Array([1.1318898], dtype=float32),\n",
       " 'z': array([0.01])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condition z to .01 in NumPyro and sample\n",
    "predictive = numpyro.infer.Predictive(\n",
    "    numpyro_model, num_samples=1, params={\"z\": np.asarray(.01)})\n",
    "predictive(sample_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditioned z to .01 in TFP and construct conditional distributions\n",
    "dist, value = jd.sample_distributions(z=.01, seed=sample_key)\n",
    "assert dist.y.loc == value.x\n",
    "assert dist.y.scale == value.z\n",
    "\n",
    "# Conditioned z to .01 in NumPyro and construct conditional distributions\n",
    "model = numpyro.handlers.substitute(numpyro_model, data={\"z\": .01})\n",
    "with numpyro.handlers.seed(rng_seed=sample_key):\n",
    "    # Under the seed context, the default behavior of a NumPyro model is the\n",
    "    # same as in Pyro: drawing prior sample.\n",
    "    model_trace = numpyro.handlers.trace(numpyro_model).get_trace()\n",
    "assert model_trace[\"y\"][\"fn\"].loc == model_trace[\"x\"][\"value\"]\n",
    "assert model_trace[\"y\"][\"fn\"].scale == model_trace[\"z\"][\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a PPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Draw 2 samples from a Normal(1., 2.) distribution\n",
    "x = stats.norm.rvs(loc=1.0, scale=2.0, size=2, random_state=1234)\n",
    "# Evaluate the log probability of the samples \n",
    "logp = stats.norm.logpdf(x, loc=1.0, scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_variable_x = stats.norm(loc=1.0, scale=2.0)\n",
    "\n",
    "x = random_variable_x.rvs(size=2, random_state=1234)\n",
    "logp = random_variable_x.logpdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'rv_continuous_frozen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mnorm(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mnorm(loc\u001b[38;5;241m=\u001b[39mx, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bmcpu/lib/python3.11/site-packages/scipy/stats/_distn_infrastructure.py:491\u001b[0m, in \u001b[0;36mrv_frozen.rvs\u001b[0;34m(self, size, random_state)\u001b[0m\n\u001b[1;32m    489\u001b[0m kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    490\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m: size, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: random_state})\n\u001b[0;32m--> 491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bmcpu/lib/python3.11/site-packages/scipy/stats/_distn_infrastructure.py:1069\u001b[0m, in \u001b[0;36mrv_generic.rvs\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_state\n\u001b[1;32m   1067\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rvs(\u001b[38;5;241m*\u001b[39margs, size\u001b[38;5;241m=\u001b[39msize, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m-> 1069\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[43mvals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# do not forget to restore the _random_state\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rndm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'rv_continuous_frozen'"
     ]
    }
   ],
   "source": [
    "x = stats.norm(loc=1.0, scale=2.0)\n",
    "y = stats.norm(loc=x, scale=0.1)\n",
    "y.rvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8371904749402057\n",
      "0.9115299858011244\n",
      "1.1045295605002439\n",
      "0.8569527358843754\n",
      "-1.3368563634713648\n"
     ]
    }
   ],
   "source": [
    "class RandomVariable:\n",
    "    def __init__(self, distribution):\n",
    "        self.distribution = distribution\n",
    "\n",
    "    def __array__(self):\n",
    "        return np.asarray(self.distribution.rvs())\n",
    "\n",
    "x = RandomVariable(stats.norm(loc=1.0, scale=2.0))\n",
    "z = RandomVariable(stats.halfnorm(loc=0., scale=1.))\n",
    "y = RandomVariable(stats.norm(loc=x, scale=z))\n",
    "\n",
    "for i in range(5):\n",
    "    print(np.asarray(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomVariable:\n",
    "    def __init__(self, distribution, value=None):\n",
    "        self.distribution = distribution\n",
    "        self.set_value(value)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(value={self.__array__()})\"\n",
    "\n",
    "    def __array__(self, dtype=None):\n",
    "        if self.value is None:\n",
    "            return np.asarray(self.distribution.rvs(), dtype=dtype)\n",
    "        return self.value\n",
    "\n",
    "    def set_value(self, value=None):\n",
    "        self.value = value\n",
    "    \n",
    "    def log_prob(self, value=None):\n",
    "        if value is not None:\n",
    "            self.set_value(value)\n",
    "        return self.distribution.logpdf(np.array(self))\n",
    "\n",
    "x = RandomVariable(stats.norm(loc=1.0, scale=2.0))\n",
    "z = RandomVariable(stats.halfnorm(loc=0., scale=1.))\n",
    "y = RandomVariable(stats.norm(loc=x, scale=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomVariable(value=1.3005379430504267)\n",
      "RandomVariable(value=3.5547158349681687)\n",
      "RandomVariable(value=-1.584682011128197)\n",
      "  Set x=5 and z=0.1\n",
      "RandomVariable(value=4.931518401510109)\n",
      "RandomVariable(value=5.008135750884229)\n",
      "RandomVariable(value=4.9915659170051265)\n",
      "  Reset z\n",
      "RandomVariable(value=4.995529441560821)\n",
      "RandomVariable(value=3.35689470946334)\n",
      "RandomVariable(value=5.279468777072529)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(y)\n",
    "\n",
    "print(f\"  Set x=5 and z=0.1\")\n",
    "x.set_value(np.asarray(5))\n",
    "z.set_value(np.asarray(0.05))\n",
    "for i in range(3):\n",
    "    print(y)\n",
    "\n",
    "print(f\"  Reset z\")\n",
    "z.set_value(None)\n",
    "for i in range(3):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.881815599614018"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observed y = 5.\n",
    "y.set_value(np.array(5.))\n",
    "\n",
    "posterior_density = lambda xval, zval: x.log_prob(xval) + z.log_prob(zval) + \\\n",
    "                y.log_prob()\n",
    "posterior_density(np.array(0.), np.array(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.881815599614018"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_prob(xval, zval, yval=5):\n",
    "    x_dist = stats.norm(loc=1.0, scale=2.0)\n",
    "    z_dist = stats.halfnorm(loc=0., scale=1.)\n",
    "    y_dist = stats.norm(loc=xval, scale=zval)\n",
    "    return x_dist.logpdf(xval) + z_dist.logpdf(zval) + y_dist.logpdf(yval)\n",
    "\n",
    "log_prob(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.390718768333718, 0.5995096105486906, 2.859734598142775)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prior_sample():\n",
    "    x = stats.norm(loc=1.0, scale=2.0).rvs()\n",
    "    z = stats.halfnorm(loc=0., scale=1.).rvs()\n",
    "    y = stats.norm(loc=x, scale=z).rvs()\n",
    "    return x, z, y\n",
    "\n",
    "prior_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2,), (2,), (2,)]\n",
      "[(2, 3, 5), (2, 3, 5), (2, 3, 5)]\n"
     ]
    }
   ],
   "source": [
    "def prior_sample(size):\n",
    "    x = stats.norm(loc=1.0, scale=2.0).rvs(size=size)\n",
    "    z = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "    y = stats.norm(loc=x, scale=z).rvs()\n",
    "    return x, z, y\n",
    "\n",
    "print([x.shape for x in prior_sample(size=(2))])\n",
    "print([x.shape for x in prior_sample(size=(2, 3, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_feature = 1000, 5\n",
    "X = np.random.randn(n_row, n_feature)\n",
    "\n",
    "def lm_prior_sample0():\n",
    "    intercept = stats.norm(loc=0, scale=10.0).rvs()\n",
    "    beta = stats.norm(loc=np.zeros(n_feature), scale=10.0).rvs()\n",
    "    sigma = stats.halfnorm(loc=0., scale=1.).rvs()\n",
    "    y_hat = X @ beta + intercept\n",
    "    y = stats.norm(loc=y_hat, scale=sigma).rvs()\n",
    "    return intercept, beta, sigma, y\n",
    "\n",
    "def lm_prior_sample(size=10):\n",
    "    if isinstance(size, int):\n",
    "        size = (size,)\n",
    "    else:\n",
    "        size = tuple(size)\n",
    "    intercept = stats.norm(loc=0, scale=10.0).rvs(size=size)\n",
    "    beta = stats.norm(loc=np.zeros(n_feature), scale=10.0).rvs(\n",
    "        size=size + (n_feature,))\n",
    "    sigma = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "    y_hat = np.squeeze(X @ beta[..., None]) + intercept[..., None]\n",
    "    y = stats.norm(loc=y_hat, scale=sigma[..., None]).rvs()\n",
    "    return intercept, beta, sigma, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), (5,), (), (1000,)]\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in lm_prior_sample0()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), (5,), (), (1000,)]\n",
      "[(10,), (10, 5), (10,), (10, 1000)]\n",
      "[(10, 3), (10, 3, 5), (10, 3), (10, 3, 1000)]\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in lm_prior_sample(size=())])\n",
    "print([x.shape for x in lm_prior_sample(size=10)])\n",
    "print([x.shape for x in lm_prior_sample(size=[10, 3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lm_prior_sample2(size=10):\n",
    "#     intercept = stats.norm(loc=0, scale=10.0).rvs(size=size)\n",
    "#     beta = stats.multivariate_normal(\n",
    "#         mean=np.zeros(n_feature), cov=10.0).rvs(size=size)\n",
    "#     sigma = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "#     y_hat = np.einsum('ij,...j->...i', X, beta) + intercept[..., None]\n",
    "#     y = stats.norm(loc=y_hat, scale=sigma[..., None]).rvs()\n",
    "#     return intercept, beta, sigma, y\n",
    "\n",
    "# print([x.shape for x in lm_prior_sample2(size=())])\n",
    "# print([x.shape for x in lm_prior_sample2(size=10)])\n",
    "# print([x.shape for x in lm_prior_sample2(size=(10, 3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.JointDistributionSequential(\"JointDistributionSequential\", batch_shape=[[], [], [], []], event_shape=[[], [5], [], [1000]], dtype=[float32, float32, float32, float32])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "jd = tfd.JointDistributionSequential([\n",
    "    tfd.Normal(0, 10),\n",
    "    tfd.Sample(tfd.Normal(0, 10), n_feature),\n",
    "    tfd.HalfNormal(1),\n",
    "    lambda sigma, beta, intercept: tfd.Independent(\n",
    "        tfd.Normal(\n",
    "            loc=tf.einsum(\"ij,...j->...i\", X, beta) + intercept[..., None],\n",
    "            scale=sigma[..., None]),\n",
    "        reinterpreted_batch_ndims=1,\n",
    "        name=\"y\")\n",
    "])\n",
    "\n",
    "print(jd)\n",
    "\n",
    "n_sample = [3, 2]\n",
    "for log_prob_part in jd.log_prob_parts(jd.sample(n_sample)):\n",
    "    assert log_prob_part.shape == n_sample"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
