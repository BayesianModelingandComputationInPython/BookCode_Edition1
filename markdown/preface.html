
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Preface — Bayesian Modeling and Computation in Python</title>
<link href="../_static/css/theme.css" rel="stylesheet"/>
<link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" rel="stylesheet" type="text/css">
<link href="../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-codeautolink.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js" rel="preload"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/togglebutton.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../_static/sphinx-thebe.js"></script>
<link href="../_static/favicon.ico" rel="shortcut icon">
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="symbollist.html" rel="next" title="Symbols"/>
<link href="foreword.html" rel="prev" title="Foreword"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-702QMHG8ST"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-702QMHG8ST');
                </script>
</link></link></link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
<h1 class="site-logo" id="site-title">Bayesian Modeling and Computation in Python</h1>
</a>
</div><form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="current nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="dedication.html">
   Dedication
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="foreword.html">
   Foreword
  </a>
</li>
<li class="toctree-l1 current active">
<a class="current reference internal" href="#">
   Preface
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="symbollist.html">
   Symbols
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_01.html">
   Chapter 1: Bayesian Inference
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_02.html">
   Chapter 2: Exploratory Analysis of Bayesian Models
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_03.html">
   Chapter 3: Linear Models and Probabilistic Programming Languages
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_04.html">
   Chapter 4: Extending Linear Models
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_05.html">
   Chapter 5: Splines
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_06.html">
   Chapter 6: Time Series
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_07.html">
   Chapter 7: Bayesian Additive Regression Trees
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_08.html">
   Chapter 8: Approximate Bayesian Computation
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_09.html">
   Chapter 9: End to End Bayesian Workflows
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_10.html">
   Chapter 10: Probabilistic Programming Languages
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="chp_11.html">
   Chapter 11: Appendiceal Topics
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="glossary.html">
   Glossary
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="references.html">
   References
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_01.html">
   Code 1: Bayesian Inference
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_02.html">
   Code 2: Exploratory Analysis of Bayesian Models
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_03.html">
   Code 3: Linear Models and Probabilistic Programming Languages
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_04.html">
   Code 4: Extending Linear Models
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_05.html">
   Code 5: Splines
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_06.html">
   Code 6: Time Series
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_07.html">
   Code 7: Bayesian Additive Regression Trees
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_08.html">
   Code 8: Approximate Bayesian Computation
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_09.html">
   Code 9: End to End Bayesian Workflows
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_10.html">
   Code 10: Probabilistic Programming Languages
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../notebooks/chp_11.html">
   Code 11: Appendiceal Topics
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1/issues/new?title=Issue%20on%20page%20%2Fmarkdown/preface.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#prior-knowledge">
   Prior knowledge
  </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#how-to-read-this-book">
   How to read this book
  </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#text-highlights">
     Text Highlights
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code">
     Code
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#boxes">
     Boxes
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#code-imports">
     Code Imports
    </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#how-to-interact-with-this-book">
     How to interact with this book
    </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#acknowledgments">
   Acknowledgments
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<div>
<div class="tex2jax_ignore mathjax_ignore section" id="preface">
<span id="id1"></span><h1>Preface<a class="headerlink" href="#preface" title="Permalink to this headline">¶</a></h1>
<p>The name Bayesian statistics is attributed to Thomas Bayes (1702–1761),
a Presbyterian minister, and amateur mathematician, who for the first
time derived what we now know as Bayes’ theorem, which was published
(posthumously) in 1763. However, one of the first people to really
develop Bayesian methods was Pierre-Simon Laplace (1749–1827), so
perhaps it would be a bit more correct to talk about Laplacian
Statistics. Nevertheless, we will honor Stigler’s law of eponymy and
also stick to tradition and keep talking about Bayesian approaches for
the rest of this book. From the pioneering days of Bayes and Laplace
(and many others) to the present day, a lot has happened - new ideas
were developed, many of which were motivated and or being enabled by
computers. The intent of this book is to provide a modern perspective on
the subject, from the fundamentals in order to build a solid foundation
into the application of a modern Bayesian workflow and tooling.</p>
<p>We write this book to help beginner Bayesian practitioners to become
intermediate modelers. We do not claim this will automatically happen
after you finish reading this book, but we hope the book can guide you
in a fruitful direction specially if you read it thoroughly, do the
exercises, apply the ideas in the book to your own problems and continue
to learn from others.</p>
<p>Specifically stated this book targets the Bayesian practitioners who are
interested in applying Bayesian models to solve data analysis problems.
Often times a distinction is made between academia and industry. This
book makes no such distinction, as it will be equally useful for a
student in a university as it is for a machine learning engineer at a
company.</p>
<p>It is our intent that upon completion of this book you will not only be
familiar with <strong>Bayesian Inference</strong> but also feel comfortable
performing <strong>Exploratory Analysis of Bayesian Models</strong>, including model
comparison, diagnostics, evaluation and communication of the results. It
is also our intent to teach all this from a modern and computational
perspective. For us, Bayesian statistics is better understood and
applied if we take a <strong>computational</strong> approach, this means, for
example, that we care more about empirically checking how our
assumptions are violated than trying to prove assumptions to be right.
This also means we use many visualizations (if we do not do more is to
avoid having a 1000 pages book). Other implications of the modeling
approach will become clear as we progress through the pages.</p>
<p>Finally, as stated in the book’s title, we use the Python programming
language in this book. More specifically, we will mainly focus on PyMC3
<span id="id2">[<a class="reference internal" href="references.html#id124">1</a>]</span> and TensorFlow Probability (TFP)
<span id="id3">[<a class="reference internal" href="references.html#id141">2</a>]</span>, as the main probabilistic programming languages
(PPLs) for model building and inference, and use ArviZ as the main
library for exploratory analysis of Bayesian models <span id="id4">[<a class="reference internal" href="references.html#id11">3</a>]</span>. We do
not intend to give an exhaustive survey and comparison of all Python
PPLs in this book, as there are many choices, and they rapidly evolve.
We instead focus on the practical aspects of Bayesian analysis.
Programming languages and libraries are merely bridges to get where we
want to go.</p>
<p>Even though our programming language of choice for this book is Python,
with few selected libraries, the statistical and modeling concepts we
cover are language and library agnostic and available in many computer
programming languages such as R, Julia, and Scala among others. A
motivated reader with knowledge of these languages but not Python can
still benefit from reading the book, especially if they find the
suitable packages that support, or code, the equivalent functionality in
their language of choice to gain hands on practice. Furthermore, the
authors encourage others to translate the code examples in this work to
other languages or frameworks. Please get in touch if you like to do so.</p>
<div class="section" id="prior-knowledge">
<span id="id5"></span><h2>Prior knowledge<a class="headerlink" href="#prior-knowledge" title="Permalink to this headline">¶</a></h2>
<p>As we write this book to help beginners to become intermediate
practitioners, we assume prior exposure, but not mastery, of the basic
ideas from Bayesian statistics such as priors, likelihoods and
posteriors as well as some basic statistical concepts like random
variables, probability distributions, expectations. For those of you
that are a little bit rusty, we provide a whole section inside Chapter <a class="reference internal" href="chp_11.html#app"><span class="std std-ref">11</span></a>,
with a refresher about basic statistical concepts.
A couple of good books explaining these concepts
in more depth are Understanding Advanced Statistical Methods
<span id="id6">[<a class="reference internal" href="references.html#id28">4</a>]</span> and Introduction to
Probability <span id="id7">[<a class="reference internal" href="references.html#id10">5</a>]</span>. The latter is a little bit more
theoretical, but both keep application in mind.</p>
<p>If you have a good understanding of statistics, either by practice or
formal training, but you have never being exposed to Bayesian
statistics, you may still use this book as an introduction to the
subject, the pace at the start (mostly the first two chapters) will be a
bit rapid, and may require a couple read-throughs.</p>
<p>We expect you to be familiar with some mathematical concepts like
integrals, derivatives, and properties of logarithms. The level of
writing will be the one generally taught at a technical high school or
maybe the first year of college in science, technology, engineering, and
mathematics careers. For those who need a refresher of such mathematical
concepts we recommend the series of videos from 3Blue1Brown <a class="footnote-reference brackets" href="#id17" id="id8">1</a>. We
will not ask you to solve many mathematical exercises instead, we will
primarily ask you to use code and an interactive computing environment
to understand and solve problems. Mathematical formulas throughout the
text are used only when they help to provide a better understanding of
Bayesian statistical modeling.</p>
<p>This book assumes that the reader comes with some knowledge of
scientific computer programming. Using the Python language we will also
use a number of specialized packages, in particular Probabilistic
Programming Languages. It will help, but is not necessary, to have fit
at least one model in a Probabilistic Programming language prior to
reading this book. For a reference on how to setup the
computation environment needed for this book, read <a class="reference external" href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1#environment-installation">environment</a> installation.</p>
</div>
<div class="section" id="how-to-read-this-book">
<span id="id9"></span><h2>How to read this book<a class="headerlink" href="#how-to-read-this-book" title="Permalink to this headline">¶</a></h2>
<p>We will use toy models to understand important concepts without the data
obscuring the main concepts and then use real datasets to approximate
real practical problems such as sampling issues, reparametrization,
prior/posterior calibration, etc. We encourage you to run these models
in an interactive code environment while reading the book.</p>
<p>We strongly encourage you to read and use the online documentation for
the various libraries. While we do our best to keep this book
self-contained, there is an extensive amount of documentation on these
tools online and referring it will aid in both learning this book, as
well as utilizing the tools on your own.</p>
<p><a class="reference internal" href="chp_01.html#chap1"><span class="std std-ref">Chapter 1</span></a> offers a refresher or a quick introduction to the basic and
central notions in Bayesian inference. The concepts from this chapter
are revisited and applied in the rest of the book.</p>
<p><a class="reference internal" href="chp_02.html#chap1bis"><span class="std std-ref">Chapter 2</span></a> offers an introduction to Exploratory Analysis of Bayesian
models. Namely introduces many of the concepts that are part of the
Bayesian workflow but are not inference itself. We apply and revisit the
concepts from this chapter in the rest of the book.</p>
<p><a class="reference internal" href="chp_03.html#chap2"><span class="std std-ref">Chapter 3</span></a> is the first chapter dedicated to a specific model
architecture. It offers an introduction to Linear Regression models and
establishes the basic groundwork for the next 5 chapters. Chapter 3 also
fully introduces the primary probabilistic programming languages used in
the book, PyMC3 and TensorFlow Probability.</p>
<p><a class="reference internal" href="chp_04.html#chap3"><span class="std std-ref">Chapter 4</span></a> extends Linear Regression models and discusses more advanced
topics like robust regression, hierarchical models and model
reparametrization. This chapter uses PyMC3 and TensorFlow Probability.</p>
<p><a class="reference internal" href="chp_05.html#chap3-5"><span class="std std-ref">Chapter 5</span></a> introduces basis functions and in particular splines as an
extension to linear models that allows us to build more flexible models.
This chapter uses PyMC3.</p>
<p><a class="reference internal" href="chp_06.html#chap4"><span class="std std-ref">Chapter 6</span></a> focuses on time series models, from modeling time series as a
regression to more complex model like ARIMA and linear Gaussian State
Space model. This chapter uses TensorFlow Probability.</p>
<p><a class="reference internal" href="chp_07.html#chap6"><span class="std std-ref">Chapter 7</span></a> offers an introduction to Bayesian additive regression trees a
non-parametric model. We discuss the interpretability of this model and
variable importance. This Chapter use PyMC3.</p>
<p><a class="reference internal" href="chp_08.html#chap8"><span class="std std-ref">Chapter 8</span></a> brings the attention to the Approximate Bayesian Computation
(ABC) framework, which is useful for problems where we do not have an
explicit formulation for the likelihood. This chapter uses PyMC3.</p>
<p><a class="reference internal" href="chp_09.html#chap9"><span class="std std-ref">Chapter 9</span></a>  gives an overview of end-to-end Bayesian workflows. It
showcases both an observational study in a business setting and an
experimental study in a research setting. This chapter uses PyMC3.</p>
<p><a class="reference internal" href="chp_10.html#chap10"><span class="std std-ref">Chapter 10</span></a>  provides a deep dive on Probabilistic Programming Languages.
Various different Probabilistic Programming languages are shown in this
chapter.</p>
<p><a class="reference internal" href="chp_11.html#app"><span class="std std-ref">Chapter 11</span></a> serves as a support when reading other chapters, as the
topics inside it are loosely related to each other, and you may not want
to read linearly.</p>
<div class="section" id="text-highlights">
<span id="id10"></span><h3>Text Highlights<a class="headerlink" href="#text-highlights" title="Permalink to this headline">¶</a></h3>
<p>Text in this book will be emphasized with <strong>bold</strong> or <em>italics</em>. <strong>Bold
text</strong> will highlight new concepts or emphasis of a concept. <em>Italic
text</em> will indicate a colloquial or non-rigorous expression. When a
specific code is mentioned they are also highlighted: <code class="docutils literal notranslate"><span class="pre">pm.sample</span></code>.</p>
</div>
<div class="section" id="code">
<span id="id11"></span><h3>Code<a class="headerlink" href="#code" title="Permalink to this headline">¶</a></h3>
<p>Blocks of code in the book are marked by a shaded box with the lines
numbers on the left. And are referenced using the chapter number
followed by the number of the Code Block. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>0
1
4
</pre></div>
</div>
<p>Every time you see a code block look for a result. Often times it is a
figure, a number, code output, or a table. Conversely most figures in
the book have an associated code block, sometimes we omit code blocks in
the book to save space, but you can still access them at the <a class="reference external" href="https://github.com/BayesianModelingandComputationInPython">GitHub
repository</a>.
The repository also includes additional material for some exercises. The
notebooks in that repository may also include additional figures, code,
or outputs not seen in the book, but that were used to develop the
models seen in the book. Also included in GitHub are instructions for
how to create a standard computation environment on whatever equipment
you have.</p>
</div>
<div class="section" id="boxes">
<span id="id12"></span><h3>Boxes<a class="headerlink" href="#boxes" title="Permalink to this headline">¶</a></h3>
<p>We use boxes to provide a quick reference for statistical, mathematical,
or (Python) Programming concepts that are important for you to know. We
also provide references for you to continue learning about the topic.</p>
<div class="admonition-central-limit-theorem admonition">
<p class="admonition-title">Central Limit Theorem</p>
<p>In probability theory, the central limit theorem
establishes that, in some situations, when independent random variables
are added, their properly normalized sum tends toward a normal
distribution even if the original variables themselves are not normally
distributed.</p>
<p>Let <span class="math notranslate nohighlight">\(X_1, X_2, X_3, ...\)</span> be i.i.d. with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard
deviation <span class="math notranslate nohighlight">\(\sigma\)</span>. As <span class="math notranslate nohighlight">\(n \rightarrow \infty\)</span>, we got:</p>
<div class="math notranslate nohighlight">
\[\sqrt{n} \left(\frac{\bar{X}-\mu}{\sigma} \right) \xrightarrow{\text{d}} \mathcal{N}(0, 1)\]</div>
<p>The book Introduction to Probability <span id="id13">[<a class="reference internal" href="references.html#id10">5</a>]</span> is a good
resource for learning many theoretical aspects of probability that are
useful in practice.</p>
</div>
</div>
<div class="section" id="code-imports">
<span id="id14"></span><h3>Code Imports<a class="headerlink" href="#code-imports" title="Permalink to this headline">¶</a></h3>
<p>In this book we use the following conventions when importing Python
packages.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Basic</span>
<span class="kn">import</span> <a class="sphinx-codeautolink-a" href="https://numpy.org/doc/stable/reference/index.html#module-numpy" title="numpy"><span class="nn">numpy</span></a> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/index.html#module-scipy" title="scipy"><span class="nn">scipy</span></a> <span class="kn">import</span> <a class="sphinx-codeautolink-a" href="https://docs.scipy.org/doc/scipy/reference/stats.html#module-scipy.stats" title="scipy.stats"><span class="n">stats</span></a>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">patsy</span> <span class="kn">import</span> <span class="n">bs</span><span class="p">,</span> <span class="n">dmatrix</span>
<span class="kn">import</span> <a class="sphinx-codeautolink-a" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot" title="matplotlib.pyplot"><span class="nn">matplotlib.pyplot</span></a> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Exploratory Analysis of Bayesian Models</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>

<span class="c1"># Probabilistic programming languages</span>
<span class="kn">import</span> <span class="nn">bambi</span> <span class="k">as</span> <span class="nn">bmb</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>

<span class="n">tfd</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span>

<span class="c1"># Computational Backend</span>
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">tt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
<p>We also use the ArviZ style <code class="docutils literal notranslate"><span class="pre">az.style.use("arviz-grayscale")</span></code></p>
</div>
<div class="section" id="how-to-interact-with-this-book">
<span id="id15"></span><h3>How to interact with this book<a class="headerlink" href="#how-to-interact-with-this-book" title="Permalink to this headline">¶</a></h3>
<p>As our audience is not a <em>Bayesian reader</em>, but a Bayesian practitioner.
We will be providing the materials to practice Bayesian inference and
exploratory analysis of Bayesian models. As leveraging computation and
code is a core skill required for modern Bayesian practitioners, we will
provide you with examples that can be played around with to build
intuition over many tries. Our expectation is that the code in this book
is read, executed, modified by the reader, and executed again many
times. We can only show so many examples in this book, but you can make
an infinite amount of examples for yourself using your computer. This
way you learn not only the statistical concepts, but how to use your
computer to generate value from those concepts.</p>
<p>Computers will also remove you from the limitations of printed text, for
example lack of colors, lack of animation, and side-by-side comparisons.
Modern Bayesian practitioners leverage the flexibility afforded by
monitors and quick computational “double checks” and we have
specifically created our examples to allow for the same level of
interactivity. We have included exercises to test your learning and
extra practice at the end of each chapter as well. Exercises are labeled
Easy (E), Medium (M), and Hard (H). Solutions are available on request.</p>
</div>
</div>
<div class="section" id="acknowledgments">
<span id="id16"></span><h2>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this headline">¶</a></h2>
<p>We are grateful to our friends and colleagues that have been kind enough
to provide their time and energy to read early drafts and propose and
provide useful feedback that helps us to improve the book and also helps
us to fix many bugs in the book. Thank you:</p>
<p>Oriol Abril-Pla, Alex Andorra, Paul Anzel, Dan Becker, Tomás Capretto,
Allen Downey, Christopher Fonnesbeck, Meenal Jhajharia, Will Kurt, Asael
Matamoros, Kevin Murphy, and Aki Vehtari.</p>
<hr class="footnotes docutils"/>
<dl class="footnote brackets">
<dt class="label" id="id17"><span class="brackets"><a class="fn-backref" href="#id8">1</a></span></dt>
<dd><p><a class="reference external" href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw">https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw</a>, we
recommend these videos even if you do not need a refresher.</p>
</dd>
</dl>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./markdown"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="foreword.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Foreword</p>
</div>
</a>
<a class="right-next" href="symbollist.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Symbols</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</div>
</div>
<footer class="footer">
<div class="container">
<p>
        
          By Martin, Kumar, Lao<br/>
        
            © Copyright 2021.<br/>
</p>
</div>
</footer>
</main>
</div>
</div>
<script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
</body>
</html>