

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>13. References &#8212; Bayesian Modeling and Computation in Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-codeautolink.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'markdown/references';</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Code 1: Bayesian Inference" href="../notebooks/chp_01.html" />
    <link rel="prev" title="12. Glossary" href="glossary.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../welcome.html">
  
  
  
  
  
  
    <p class="title logo__title">Bayesian Modeling and Computation in Python</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 0</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dedication.html">Dedication</a></li>
<li class="toctree-l1"><a class="reference internal" href="foreword.html">Foreword</a></li>
<li class="toctree-l1"><a class="reference internal" href="preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="symbollist.html">Symbols</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 1</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="chp_01.html">1. Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_02.html">2. Exploratory Analysis of Bayesian Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_03.html">3. Linear Models and Probabilistic Programming Languages</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_04.html">4. Extending Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_05.html">5. Splines</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_06.html">6. Time Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_07.html">7. Bayesian Additive Regression Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_08.html">8. Approximate Bayesian Computation</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_09.html">9. End to End Bayesian Workflows</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_10.html">10. Probabilistic Programming Languages</a></li>
<li class="toctree-l1"><a class="reference internal" href="chp_11.html">11. Appendiceal Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">12. Glossary</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">13. References</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_01.html">Code 1: Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_02.html">Code 2: Exploratory Analysis of Bayesian Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_03.html">Code 3: Linear Models and Probabilistic Programming Languages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_04.html">Code 4: Extending Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_05.html">Code 5: Splines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_06.html">Code 6: Time Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_07.html">Code 7: Bayesian Additive Regression Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_08.html">Code 8: Approximate Bayesian Computation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_09.html">Code 9: End to End Bayesian Workflows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_10.html">Code 10: Probabilistic Programming Languages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/chp_11.html">Code 11: Appendiceal Topics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../solutions/chp_01.html">Solutions 1: Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../solutions/chp_02.html">Solutions 2: Exploratory Analysis of Bayesian models</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/BayesianModelingandComputationInPython/BookCode_Edition1/issues/new?title=Issue%20on%20page%20%2Fmarkdown/references.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>References</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="references">
<span id="id1"></span><h1><span class="section-number">13. </span>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h1>
<div class="docutils container" id="id2">
<div class="citation" id="id124" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>John Salvatier, Thomas V Wiecki, and Christopher Fonnesbeck. Probabilistic programming in python using pymc3. <em>PeerJ Computer Science</em>, 2:e55, 2016.</p>
</div>
<div class="citation" id="id141" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Joshua V. Dillon, Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas Vasudevan, Dave Moore, Brian Patton, Alex Alemi, Matt Hoffman, and Rif A Saurous. Tensorflow distributions. <em>arXiv preprint arXiv:1711.10604</em>, 2017.</p>
</div>
<div class="citation" id="id11" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Ravin Kumar, Colin Carroll, Ari Hartikainen, and Osvaldo Martin. Arviz a unified library for exploratory analysis of bayesian models in python. <em>Journal of Open Source Software</em>, 4(33):1143, 2019.</p>
</div>
<div class="citation" id="id28" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>P. Westfall and K.S.S. Henning. <em>Understanding Advanced Statistical Methods</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. Taylor &amp; Francis, 2013. ISBN 9781466512108.</p>
</div>
<div class="citation" id="id10" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></span>
<p>J.K. Blitzstein and J. Hwang. <em>Introduction to Probability, Second Edition</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. CRC Press, 2019. ISBN 9780429766732.</p>
</div>
<div class="citation" id="id25" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></span>
<p>Wikipedia contributors. Conceptual model — Wikipedia, the free encyclopedia. Page Version ID: 952394363. URL: <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Conceptual_model&amp;oldid=952394363">https://en.wikipedia.org/w/index.php?title=Conceptual_model&amp;oldid=952394363</a>.</p>
</div>
<div class="citation" id="id106" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></span>
<p>Nicholas Metropolis, Arianna W Rosenbluth, Marshall N Rosenbluth, Augusta H Teller, and Edward Teller. Equation of state calculations by fast computing machines. <em>The journal of chemical physics</em>, 21(6):1087–1092, 1953.</p>
</div>
<div class="citation" id="id107" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<p>WK HASTINGS. Monte carlo sampling methods using markov chains and their applications. <em>Biometrika</em>, 57(1):97–109, 1970.</p>
</div>
<div class="citation" id="id108" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></span>
<p>Marshall N Rosenbluth. Genesis of the monte carlo algorithm for statistical mechanics. In <em>AIP Conference Proceedings</em>, volume 690, 22–30. American Institute of Physics, 2003.</p>
</div>
<div class="citation" id="id33" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></span>
<p>R. McElreath. <em>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. CRC Press, 2020. ISBN 9781482253481.</p>
</div>
<div class="citation" id="id99" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></span>
<p>Daniel Lakens, Federico G. Adolfi, Casper J. Albers, Farid Anvari, Matthew A. J. Apps, Shlomo E. Argamon, Thom Baguley, Raymond B. Becker, Stephen D. Benning, Daniel E. Bradford, Erin M. Buchanan, Aaron R. Caldwell, Ben Van Calster, Rickard Carlsson, Sau-Chin Chen, Bryan Chung, Lincoln J. Colling, Gary S. Collins, Zander Crook, Emily S. Cross, Sameera Daniels, Henrik Danielsson, Lisa DeBruine, Daniel J. Dunleavy, Brian D. Earp, Michele I. Feist, Jason D. Ferrell, James G. Field, Nicholas W. Fox, Amanda Friesen, Caio Gomes, Monica Gonzalez-Marquez, James A. Grange, Andrew P. Grieve, Robert Guggenberger, James Grist, Anne-Laura van Harmelen, Fred Hasselman, Kevin D. Hochard, Mark R. Hoffarth, Nicholas P. Holmes, Michael Ingre, Peder M. Isager, Hanna K. Isotalus, Christer Johansson, Konrad Juszczyk, David A. Kenny, Ahmed A. Khalil, Barbara Konat, Junpeng Lao, Erik Gahner Larsen, Gerine M. A. Lodder, Jiří Lukavský, Christopher R. Madan, David Manheim, Stephen R. Martin, Andrea E. Martin, Deborah G. Mayo, Randy J. McCarthy, Kevin McConway, Colin McFarland, Amanda Q. X. Nio, Gustav Nilsonne, Cilene Lino de Oliveira, Jean-Jacques Orban de Xivry, Sam Parsons, Gerit Pfuhl, Kimberly A. Quinn, John J. Sakon, S. Adil Saribay, Iris K. Schneider, Manojkumar Selvaraju, Zsuzsika Sjoerds, Samuel G. Smith, Tim Smits, Jeffrey R. Spies, Vishnu Sreekumar, Crystal N. Steltenpohl, Neil Stenhouse, Wojciech Swiatkowski, Miguel A. Vadillo, Marcel A. L. M. Van Assen, Matt N. Williams, Samantha E. Williams, Donald R. Williams, Tal Yarkoni, Ignazio Ziano, and Rolf A. Zwaan. Justify your alpha. <em>Nature Human Behaviour</em>, 2(3):168–171, 2018.</p>
</div>
<div class="citation" id="id100" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>David Deming. Do extraordinary claims require extraordinary evidence? <em>Philosophia</em>, 44(4):1319–1331, 2016.</p>
</div>
<div class="citation" id="id63" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></span>
<p>Andrew Gelman, Daniel Simpson, and Michael Betancourt. The prior can often only be understood in the context of the likelihood. <em>Entropy</em>, 19(10):555, 2017.</p>
</div>
<div class="citation" id="id34" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>John W. Tukey. <em>Exploratory Data Analysis</em>. Addison-Wesley, 1977.</p>
</div>
<div class="citation" id="id27" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>15<span class="fn-bracket">]</span></span>
<p>Persi Diaconis. <em>Theories of Data Analysis: From Magical Thinking Through Classical Statistics</em>, chapter 1, pages 1–36. John Wiley &amp; Sons, Ltd, 2006.</p>
</div>
<div class="citation" id="id20" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></span>
<p>Jonah Gabry, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman. Visualization in bayesian workflow. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, 182(2):389–402, 2019.</p>
</div>
<div class="citation" id="id78" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>17<span class="fn-bracket">]</span></span>
<p>Andrew Gelman, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, and Martin Modrák. Bayesian workflow. <em>arXiv preprint arXiv:2011.01808</em>, 2020.</p>
</div>
<div class="citation" id="id3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>A. Gelman, J.B. Carlin, H.S. Stern, D.B. Dunson, A. Vehtari, and D.B. Rubin. <em>Bayesian Data Analysis, Third Edition</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. Taylor &amp; Francis, 2013. ISBN 9781439840955.</p>
</div>
<div class="citation" id="id13" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, and Paul-Christian Bürkner. Rank-Normalization, Folding, and Localization: An Improved $\widehat R$ for Assessing Convergence of MCMC. <em>Bayesian Analysis</em>, pages 1 – 38, 2021. URL: <a class="reference external" href="https://doi.org/10.1214/20-BA1221">https://doi.org/10.1214/20-BA1221</a>, <a class="reference external" href="https://doi.org/10.1214/20-BA1221">doi:10.1214/20-BA1221</a>.</p>
</div>
<div class="citation" id="id171" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>20<span class="fn-bracket">]</span></span>
<p>Stephan Hoyer and Joe Hamman. Xarray: nd labeled arrays and datasets in python. <em>Journal of Open Research Software</em>, 2017.</p>
</div>
<div class="citation" id="id18" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>21<span class="fn-bracket">]</span></span>
<p>Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. <em>Journal of the American statistical Association</em>, 102(477):359–378, 2007.</p>
</div>
<div class="citation" id="id19" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>22<span class="fn-bracket">]</span></span>
<p>Aki Vehtari, Daniel Simpson, Andrew Gelman, Yuling Yao, and Jonah Gabry. Pareto smoothed importance sampling. <em>arXiv preprint arXiv:1507.02646</em>, 2021.</p>
</div>
<div class="citation" id="id170" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>23<span class="fn-bracket">]</span></span>
<p>Aki. Vehtari and Jonah. Gabry. Loo glossary. https://mc-stan.org/loo/reference/loo-glossary.html.</p>
</div>
<div class="citation" id="id147" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Topi Paananen, Juho Piironen, Paul-Christian Bürkner, and Aki Vehtari. Implicitly adaptive importance sampling. <em>Statistics and Computing</em>, 31(2):1–19, 2021.</p>
</div>
<div class="citation" id="id26" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>25<span class="fn-bracket">]</span></span>
<p>Jennifer A Hoeting, David Madigan, Adrian E Raftery, and Chris T Volinsky. Bayesian model averaging: a tutorial (with comments by m. clyde, david draper and ei george, and a rejoinder by the authors. <em>Statistical science</em>, 14(4):382–417, 1999.</p>
</div>
<div class="citation" id="id22" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>26<span class="fn-bracket">]</span></span>
<p>Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using stacking to average bayesian predictive distributions (with discussion). <em>Bayesian Analysis</em>, 13(3):917–1007, 2018.</p>
</div>
<div class="citation" id="id115" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>27<span class="fn-bracket">]</span></span>
<p>Donald B Rubin. Estimation in parallel randomized experiments. <em>Journal of Educational Statistics</em>, 6(4):377–401, 1981.</p>
</div>
<div class="citation" id="id58" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>28<span class="fn-bracket">]</span></span>
<p>Allison Marie Horst, Alison Presmanes Hill, and Kristen B Gorman. <em>palmerpenguins: Palmer Archipelago (Antarctica) penguin data</em>. 2020. R package version 0.1.0. URL: <a class="reference external" href="https://allisonhorst.github.io/palmerpenguins/">https://allisonhorst.github.io/palmerpenguins/</a>, <a class="reference external" href="https://doi.org/10.5281/zenodo.3960218">doi:10.5281/zenodo.3960218</a>.</p>
</div>
<div class="citation" id="id128" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>29<span class="fn-bracket">]</span></span>
<p>Dan Piponi, Dave Moore, and Joshua V. Dillon. Joint distributions for tensorflow probability. <em>arXiv preprint arXiv:2001.11819</em>, 2020.</p>
</div>
<div class="citation" id="id133" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>30<span class="fn-bracket">]</span></span>
<p>Junpeng Lao, Christopher Suter, Ian Langmore, Cyril Chimisov, Ashish Saxena, Pavel Sountsov, Dave Moore, Rif A Saurous, Matthew D Hoffman, and Joshua V. Dillon. Tfp.mcmc: modern markov chain monte carlo tools built for modern hardware. <em>arXiv preprint arXiv:2002.01184</em>, 2020.</p>
</div>
<div class="citation" id="id60" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>31<span class="fn-bracket">]</span></span>
<p>J. Fox. <em>Applied Regression Analysis and Generalized Linear Models</em>. SAGE Publications, 2015. ISBN 9781483321318.</p>
</div>
<div class="citation" id="id65" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>32<span class="fn-bracket">]</span></span>
<p>Kristen B Gorman, Tony D Williams, and William R Fraser. Ecological sexual dimorphism and environmental variability within a community of antarctic penguins (genus pygoscelis). <em>PloS one</em>, 9(3):e90081, 2014.</p>
</div>
<div class="citation" id="id118" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>33<span class="fn-bracket">]</span></span>
<p>Tomás Capretto, Camen Piho, Ravin Kumar, Jacob Westfall, Tal Yarkoni, and Osvaldo A Martin. Bambi: a simple interface for fitting bayesian linear models in python. <em>arXiv preprint arXiv:2012.10754</em>, 2020.</p>
</div>
<div class="citation" id="id82" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>34<span class="fn-bracket">]</span></span>
<p>Douglas Bates, Martin Mächler, Ben Bolker, and Steve Walker. Fitting linear mixed-effects models using lme4. <em>arXiv preprint arXiv:1406.5823</em>, 2014.</p>
</div>
<div class="citation" id="id81" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>35<span class="fn-bracket">]</span></span>
<p>Jose Pinheiro, Douglas Bates, Saikat DebRoy, Deepayan Sarkar, and R Core Team. <em>nlme: Linear and Nonlinear Mixed Effects Models</em>. 2020. R package version 3.1-151. URL: <a class="reference external" href="https://CRAN.R-project.org/package=nlme">https://CRAN.R-project.org/package=nlme</a>.</p>
</div>
<div class="citation" id="id83" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>36<span class="fn-bracket">]</span></span>
<p>Jonah Gabry and Ben Goodrich. Estimating generalized (non-)linear models with group-specific terms with rstanarm. 6 2020. URL: <a class="reference external" href="https://mc-stan.org/rstanarm/articles/glmer.html">https://mc-stan.org/rstanarm/articles/glmer.html</a>.</p>
</div>
<div class="citation" id="id84" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>37<span class="fn-bracket">]</span></span>
<p>Paul-Christian Bürkner. Brms: an r package for bayesian multilevel models using stan. <em>Journal of statistical software</em>, 80(1):1–28, 2017.</p>
</div>
<div class="citation" id="id79" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>38<span class="fn-bracket">]</span></span>
<p>C. Davidson-Pilon. <em>Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference</em>. Addison-Wesley Data &amp; Analytics Series. Pearson Education, 2015. ISBN 9780133902921.</p>
</div>
<div class="citation" id="id172" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>39<span class="fn-bracket">]</span></span>
<p>Brian Greenhill, Michael D Ward, and Audrey Sacks. The separation plot: a new visual method for evaluating the fit of binary models. <em>American Journal of Political Science</em>, 55(4):991–1002, 2011.</p>
</div>
<div class="citation" id="id62" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>40<span class="fn-bracket">]</span></span>
<p>A. Gelman, J. Hill, and A. Vehtari. <em>Regression and Other Stories</em>. Analytical Methods for Social Research. Cambridge University Press, 2020. ISBN 9781107023987.</p>
</div>
<div class="citation" id="id68" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>41<span class="fn-bracket">]</span></span>
<p>O. Martin. <em>Bayesian Analysis with Python: Introduction to Statistical Modeling and Probabilistic Programming Using PyMC3 and ArviZ, 2nd Edition</em>. Packt Publishing, 2018. ISBN 9781789341652.</p>
</div>
<div class="citation" id="id119" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>42<span class="fn-bracket">]</span></span>
<p>Frank E Grubbs. Procedures for detecting outlying observations in samples. <em>Technometrics</em>, 11(1):1–21, 1969.</p>
</div>
<div class="citation" id="id135" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>43<span class="fn-bracket">]</span></span>
<p>Michael Betancourt. Towards a principled bayesian workflow. <a class="reference external" href="https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html">https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html</a>, 4 2020.</p>
</div>
<div class="citation" id="id80" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>44<span class="fn-bracket">]</span></span>
<p>Andrew Gelman. Analysis of variance—why it is more important than ever. <em>The annals of statistics</em>, 33(1):1–53, 2005.</p>
</div>
<div class="citation" id="id86" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>45<span class="fn-bracket">]</span></span>
<p>Radford M Neal. Slice sampling. <em>The annals of statistics</em>, 31(3):705–767, 2003.</p>
</div>
<div class="citation" id="id173" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>46<span class="fn-bracket">]</span></span>
<p>Omiros Papaspiliopoulos, Gareth O Roberts, and Martin Sköld. A general framework for the parametrization of hierarchical models. <em>Statistical Science</em>, pages 59–73, 2007.</p>
</div>
<div class="citation" id="id164" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>47<span class="fn-bracket">]</span></span>
<p>Michael Betancourt. Hierarchical modeling. <a class="reference external" href="https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html">https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html</a>, 11 2020.</p>
</div>
<div class="citation" id="id122" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>48<span class="fn-bracket">]</span></span>
<p>Nathan P Lemoine. Moving beyond noninformative priors: why and how to choose weakly informative priors in bayesian analyses. <em>Oikos</em>, 128(7):912–928, 2019.</p>
</div>
<div class="citation" id="id4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>49<span class="fn-bracket">]</span></span>
<p>S.N. Wood. <em>Generalized Additive Models: An Introduction with R, Second Edition</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. CRC Press, 2017. ISBN 9781498728379.</p>
</div>
<div class="citation" id="id120" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>50<span class="fn-bracket">]</span></span>
<p>Catherine Potvin, Martin J Lechowicz, and Serge Tardif. The statistical analysis of ecophysiological response curves obtained from experiments involving repeated measures. <em>Ecology</em>, 71(4):1389–1400, 1990.</p>
</div>
<div class="citation" id="id121" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>51<span class="fn-bracket">]</span></span>
<p>Eric J Pedersen, David L Miller, Gavin L Simpson, and Noam Ross. Hierarchical generalized additive models in ecology: an introduction with mgcv. <em>PeerJ</em>, 7:e6876, 2019.</p>
</div>
<div class="citation" id="id91" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>52<span class="fn-bracket">]</span></span>
<p>Carl Edward Rasmussen and Christopher K. I. Williams. <em>Gaussian Processes for Machine Learning</em>. The MIT Press, Cambridge, Mass, 2005. ISBN 978-0-262-18253-9.</p>
</div>
<div class="citation" id="id125" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>53<span class="fn-bracket">]</span></span>
<p>Sean J Taylor and Benjamin Letham. Forecasting at scale. <em>The American Statistician</em>, 72(1):37–45, 2018.</p>
</div>
<div class="citation" id="id126" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>54<span class="fn-bracket">]</span></span>
<p>Ryan Prescott Adams and David JC MacKay. Bayesian online changepoint detection. <em>arXiv preprint arXiv:0710.3742</em>, 2007.</p>
</div>
<div class="citation" id="id160" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>55<span class="fn-bracket">]</span></span>
<p>G. Strang. <em>Introduction to Linear Algebra</em>. Wellesley-Cambridge Press, 2009. ISBN 9780980232714.</p>
</div>
<div class="citation" id="id127" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>56<span class="fn-bracket">]</span></span>
<p>Andrew C Harvey and Neil Shephard. Structural time series models. <em>Handbook of Statistics,(edited by GS Maddala, CR Rao and HD Vinod)</em>, 11:261–302, 1993.</p>
</div>
<div class="citation" id="id130" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>57<span class="fn-bracket">]</span></span>
<p>G.E.P. Box, G.M. Jenkins, and G.C. Reinsel. <em>Time Series Analysis: Forecasting and Control</em>. Wiley Series in Probability and Statistics. Wiley, 2008. ISBN 9780470272848.</p>
</div>
<div class="citation" id="id132" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>58<span class="fn-bracket">]</span></span>
<p>R. Shumway and D. Stoffer. <em>Time Series: A Data Analysis Approach Using R</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. CRC Press, 2019. ISBN 9781000001563.</p>
</div>
<div class="citation" id="id134" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>59<span class="fn-bracket">]</span></span>
<p>M. West and J. Harrison. <em>Bayesian Forecasting and Dynamic Models</em>. Springer Series in Statistics. Springer New York, 2013. ISBN 9781475793659.</p>
</div>
<div class="citation" id="id129" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>60<span class="fn-bracket">]</span></span>
<p>S. Särkkä. <em>Bayesian Filtering and Smoothing</em>. Bayesian Filtering and Smoothing. Cambridge University Press, 2013. ISBN 9781107030657.</p>
</div>
<div class="citation" id="id131" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>61<span class="fn-bracket">]</span></span>
<p>James Durbin and Siem Jan Koopman. <em>Time series analysis by state space methods</em>. Oxford university press, 2012.</p>
</div>
<div class="citation" id="id161" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>62<span class="fn-bracket">]</span></span>
<p>Mohinder S Grewal and Angus P Andrews. <em>Kalman filtering: Theory and Practice with MATLAB</em>. John Wiley &amp; Sons, 2014.</p>
</div>
<div class="citation" id="id38" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>63<span class="fn-bracket">]</span></span>
<p>N. Chopin and O. Papaspiliopoulos. <em>An Introduction to Sequential Monte Carlo</em>. Springer Series in Statistics. Springer International Publishing, 2020. ISBN 9783030478445.</p>
</div>
<div class="citation" id="id123" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>64<span class="fn-bracket">]</span></span>
<p>Paul-Christian Bürkner, Jonah Gabry, and Aki Vehtari. Approximate leave-future-out cross-validation for bayesian time series models. <em>Journal of Statistical Computation and Simulation</em>, 90(14):2499–2523, 2020.</p>
</div>
<div class="citation" id="id166" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>65<span class="fn-bracket">]</span></span>
<p>Carlos M. Carvalho, Nicholas G. Polson, and James G. Scott. The horseshoe estimator for sparse signals. <em>Biometrika</em>, 97(2):465–480, 2010.</p>
</div>
<div class="citation" id="id168" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>66<span class="fn-bracket">]</span></span>
<p>Juho Piironen, Aki Vehtari, and others. Sparsity information and regularization in the horseshoe and other shrinkage priors. <em>Electronic Journal of Statistics</em>, 11(2):5018–5051, 2017.</p>
</div>
<div class="citation" id="id167" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>67<span class="fn-bracket">]</span></span>
<p>Juho Piironen and Aki Vehtari. On the hyperprior choice for the global shrinkage parameter in the horseshoe prior. In <em>Artificial Intelligence and Statistics</em>, 905–913. PMLR, 2017.</p>
</div>
<div class="citation" id="id169" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>68<span class="fn-bracket">]</span></span>
<p>Gabriel Riutort-Mayol, Paul-Christian Bürkner, Michael R Andersen, Arno Solin, and Aki Vehtari. Practical hilbert space approximate bayesian gaussian processes for probabilistic programming. <em>arXiv preprint arXiv:2004.11408</em>, 2020.</p>
</div>
<div class="citation" id="id148" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>69<span class="fn-bracket">]</span></span>
<p>Leo Breiman. Statistical modeling: the two cultures (with comments and a rejoinder by the author). <em>Statistical science</em>, 16(3):199–231, 2001.</p>
</div>
<div class="citation" id="id6" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>70<span class="fn-bracket">]</span></span>
<p>Z.H. Zhou. <em>Ensemble Methods: Foundations and Algorithms</em>. Chapman &amp; Hall/CRC data mining and knowledge discovery series. CRC Press, 2012. ISBN 9781439830055.</p>
</div>
<div class="citation" id="id5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>71<span class="fn-bracket">]</span></span>
<p>Hugh A. Chipman, Edward I. George, and Robert E. McCulloch. Bart: bayesian additive regression trees. <em>The Annals of Applied Statistics</em>, 4(1):266–298, 2010.</p>
</div>
<div class="citation" id="id67" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>72<span class="fn-bracket">]</span></span>
<p>Veronika Ročková and Enakshi Saha. On theory for bart. In <em>The 22nd International Conference on Artificial Intelligence and Statistics</em>, 2839–2848. PMLR, 2019.</p>
</div>
<div class="citation" id="id9" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>73<span class="fn-bracket">]</span></span>
<p>Balaji Lakshminarayanan, Daniel Roy, and Yee Whye Teh. Particle gibbs for bayesian additive regression trees. In <em>Artificial Intelligence and Statistics</em>, 553–561. PMLR, 2015.</p>
</div>
<div class="citation" id="id75" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>74<span class="fn-bracket">]</span></span>
<p>C. Molnar. <em>Interpretable Machine Learning</em>. Lulu.com, 2020. ISBN 9780244768522.</p>
</div>
<div class="citation" id="id74" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>75<span class="fn-bracket">]</span></span>
<p>Christoph Molnar, Giuseppe Casalicchio, and Bernd Bischl. Interpretable machine learning–a brief history, state-of-the-art and challenges. In <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>, 417–431. Springer, 2020.</p>
</div>
<div class="citation" id="id72" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>76<span class="fn-bracket">]</span></span>
<p>Jerome H Friedman. Greedy function approximation: a gradient boosting machine. <em>Annals of statistics</em>, pages 1189–1232, 2001.</p>
</div>
<div class="citation" id="id73" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>77<span class="fn-bracket">]</span></span>
<p>Alex Goldstein, Adam Kapelner, Justin Bleich, and Emil Pitkin. Peeking inside the black box: visualizing statistical learning with plots of individual conditional expectation. <em>journal of Computational and Graphical Statistics</em>, 24(1):44–65, 2015.</p>
</div>
<div class="citation" id="id66" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>78<span class="fn-bracket">]</span></span>
<p>Yi Liu, Veronika Ročková, and Yuexi Wang. Variable selection with abc bayesian forests. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 2019.</p>
</div>
<div class="citation" id="id71" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>79<span class="fn-bracket">]</span></span>
<p>Colin J. Carlson. Embarcadero: species distribution modelling with bayesian additive regression trees in r. <em>Methods in Ecology and Evolution</em>, 11(7):850–858, 2020.</p>
</div>
<div class="citation" id="id76" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>80<span class="fn-bracket">]</span></span>
<p>Justin Bleich, Adam Kapelner, Edward I George, and Shane T Jensen. Variable selection for bart: an application to gene regulation. <em>The Annals of Applied Statistics</em>, pages 1750–1781, 2014.</p>
</div>
<div class="citation" id="id149" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>81<span class="fn-bracket">]</span></span>
<p>Leo Breiman. Random forests. <em>Machine learning</em>, 45(1):5–32, 2001.</p>
</div>
<div class="citation" id="id8" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>82<span class="fn-bracket">]</span></span>
<p>Matej Balog and Yee Whye Teh. The mondrian process for machine learning. <em>arXiv preprint arXiv:1507.05181</em>, 2015.</p>
</div>
<div class="citation" id="id7" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>83<span class="fn-bracket">]</span></span>
<p>Daniel M Roy and Yee Whye Teh. The mondrian process. In <em>Proceedings of the 21st International Conference on Neural Information Processing Systems</em>, 1377–1384. 2008.</p>
</div>
<div class="citation" id="id77" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>84<span class="fn-bracket">]</span></span>
<p>Mikael Sunnåker, Alberto Giovanni Busetto, Elina Numminen, Jukka Corander, Matthieu Foll, and Christophe Dessimoz. Approximate bayesian computation. <em>PLoS computational biology</em>, 9(1):e1002803, 2013.</p>
</div>
<div class="citation" id="id56" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>85<span class="fn-bracket">]</span></span>
<p>Ritabrata Dutta, Marcel Schoengens, Jukka-Pekka Onnela, and Antonietta Mira. Abcpy: a user-friendly, extensible, and parallel library for approximate bayesian computation. In <em>Proceedings of the platform for advanced scientific computing conference</em>, 1–9. 2017.</p>
</div>
<div class="citation" id="id55" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>86<span class="fn-bracket">]</span></span>
<p>Jarno Lintusaari, Henri Vuollekoski, Antti Kangasraasio, Kusti Skytén, Marko Jarvenpaa, Pekka Marttinen, Michael U Gutmann, Aki Vehtari, Jukka Corander, and Samuel Kaski. Elfi: engine for likelihood-free inference. <em>Journal of Machine Learning Research</em>, 19(16):1–7, 2018.</p>
</div>
<div class="citation" id="id57" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>87<span class="fn-bracket">]</span></span>
<p>Emmanuel Klinger, Dennis Rickert, and Jan Hasenauer. Pyabc: distributed, likelihood-free inference. <em>Bioinformatics</em>, 34(20):3591–3593, 2018.</p>
</div>
<div class="citation" id="id153" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>88<span class="fn-bracket">]</span></span>
<p>Georges Darmois. Sur les lois de probabilitéa estimation exhaustive. <em>CR Acad. Sci. Paris</em>, 260(1265):85, 1935.</p>
</div>
<div class="citation" id="id152" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>89<span class="fn-bracket">]</span></span>
<p>Bernard Osgood Koopman. On distributions admitting a sufficient statistic. <em>Transactions of the American Mathematical society</em>, 39(3):399–409, 1936.</p>
</div>
<div class="citation" id="id151" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>90<span class="fn-bracket">]</span></span>
<p>Edwin James George Pitman. Sufficient statistics and intrinsic accuracy. In <em>Mathematical Proceedings of the cambridge Philosophical society</em>, volume 32, 567–579. Cambridge University Press, 1936.</p>
</div>
<div class="citation" id="id150" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>91<span class="fn-bracket">]</span></span>
<p>Erling Bernhard Andersen. Sufficiency and exponential families for discrete sample spaces. <em>Journal of the American Statistical Association</em>, 65(331):1248–1255, 1970.</p>
</div>
<div class="citation" id="id48" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>92<span class="fn-bracket">]</span></span>
<p>Fernando Pérez-Cruz. Kullback-leibler divergence estimation of continuous distributions. In <em>2008 IEEE international symposium on information theory</em>, 1666–1670. IEEE, 2008.</p>
</div>
<div class="citation" id="id47" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>93<span class="fn-bracket">]</span></span>
<p>Bai Jiang. Approximate bayesian computation with kullback-leibler divergence as data discrepancy. In <em>International conference on artificial intelligence and statistics</em>, 1711–1721. PMLR, 2018.</p>
</div>
<div class="citation" id="id46" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>94<span class="fn-bracket">]</span></span>
<p>Espen Bernton, Pierre E Jacob, Mathieu Gerber, and Christian P Robert. Approximate bayesian computation with the wasserstein distance. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 81(2):235–269, 2019.</p>
</div>
<div class="citation" id="id49" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>95<span class="fn-bracket">]</span></span>
<p>Jon Louis Bentley. Multidimensional binary search trees used for associative searching. <em>Communications of the ACM</em>, 18(9):509–517, 1975.</p>
</div>
<div class="citation" id="id50" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>96<span class="fn-bracket">]</span></span>
<p>S.A. Sisson, Y. Fan, and M. Beaumont. <em>Handbook of Approximate Bayesian Computation</em>. Chapman &amp; Hall/CRC Handbooks of Modern Statistical Methods. CRC Press, 2018. ISBN 9781439881514.</p>
</div>
<div class="citation" id="id53" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>97<span class="fn-bracket">]</span></span>
<p>Mark A. Beaumont, Wenyang Zhang, and David J Balding. Approximate bayesian computation in population genetics. <em>Genetics</em>, 162(4):2025–2035, 2002.</p>
</div>
<div class="citation" id="id54" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>98<span class="fn-bracket">]</span></span>
<p>Mark A. Beaumont. Approximate bayesian computation in evolution and ecology. <em>Annual review of ecology, evolution, and systematics</em>, 41:379–406, 2010.</p>
</div>
<div class="citation" id="id51" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>99<span class="fn-bracket">]</span></span>
<p>Pierre Pudlo, Jean-Michel Marin, Arnaud Estoup, Jean-Marie Cornuet, Mathieu Gautier, and Christian P Robert. Reliable abc model choice via random forests. <em>Bioinformatics</em>, 32(6):859–866, 2016.</p>
</div>
<div class="citation" id="id40" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>100<span class="fn-bracket">]</span></span>
<p>John W. Tukey. Modern Techniques in Data Analysis. In <em>proceesings of the Sponsored Regional Research Conference</em>. 1977.</p>
</div>
<div class="citation" id="id41" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>101<span class="fn-bracket">]</span></span>
<p>Glen D Rayner and Helen L MacGillivray. Numerical maximum likelihood estimation for the g-and-k and generalized g-and-h distributions. <em>Statistics and Computing</em>, 12(1):57–75, 2002.</p>
</div>
<div class="citation" id="id45" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>102<span class="fn-bracket">]</span></span>
<p>Dennis Prangle. Gk: an r package for the g-and-k and generalised g-and-h distributions. <em>arXiv preprint arXiv:1706.06889</em>, 2017.</p>
</div>
<div class="citation" id="id42" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>103<span class="fn-bracket">]</span></span>
<p>Christopher C Drovandi and Anthony N Pettitt. Likelihood-free bayesian estimation of multivariate quantile distributions. <em>Computational Statistics &amp; Data Analysis</em>, 55(9):2541–2556, 2011.</p>
</div>
<div class="citation" id="id43" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>104<span class="fn-bracket">]</span></span>
<p>A.L. Bowley. <em>Elements of Statistics</em>. Number v. 2 in Elements of Statistics. P.S. King, 1920.</p>
</div>
<div class="citation" id="id44" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>105<span class="fn-bracket">]</span></span>
<p>JJA Moors. A quantile alternative for kurtosis. <em>Journal of the Royal Statistical Society: Series D (The Statistician)</em>, 37(1):25–32, 1988.</p>
</div>
<div class="citation" id="id39" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>106<span class="fn-bracket">]</span></span>
<p>Jean-Michel Marin, Pierre Pudlo, Christian P Robert, and Robin J Ryder. Approximate bayesian computational methods. <em>Statistics and Computing</em>, 22(6):1167–1180, 2012.</p>
</div>
<div class="citation" id="id52" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>107<span class="fn-bracket">]</span></span>
<p>Mark A. Beaumont. Approximate bayesian computation. <em>Annual review of statistics and its application</em>, 6:379–403, 2019.</p>
</div>
<div class="citation" id="id61" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>108<span class="fn-bracket">]</span></span>
<p>Christian P Robert, Jean-Marie Cornuet, Jean-Michel Marin, and Natesh S Pillai. Lack of confidence in approximate bayesian computation model choice. <em>Proceedings of the National Academy of Sciences</em>, 108(37):15112–15117, 2011.</p>
</div>
<div class="citation" id="id64" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>109<span class="fn-bracket">]</span></span>
<p>François-David Collin, Arnaud Estoup, Jean-Michel Marin, and Louis Raynal. Bringing abc inference to the machine learning realm: abcranger, an optimized random forests library for abc. In <em>JOBIM 2020</em>, volume 2020. 2020.</p>
</div>
<div class="citation" id="id143" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>110<span class="fn-bracket">]</span></span>
<p>Peter Bickel, Bo Li, Thomas Bengtsson, and others. Sharp failure rates for the bootstrap particle filter in high dimensions. In <em>Pushing the limits of contemporary statistics: Contributions in honor of Jayanta K. Ghosh</em>, pages 318–329. Institute of Mathematical Statistics, 2008.</p>
</div>
<div class="citation" id="id174" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>111<span class="fn-bracket">]</span></span>
<p>S.P. Otto and T. Day. <em>A Biologist's Guide to Mathematical Modeling in Ecology and Evolution</em>. Princeton University Press, 2011. ISBN 9781400840915.</p>
</div>
<div class="citation" id="id12" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>112<span class="fn-bracket">]</span></span>
<p>D. R. Cox. <em>Principles of statistical inference</em>. Cambridge University Press, 2006. ISBN 978-0521685672.</p>
</div>
<div class="citation" id="id175" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>113<span class="fn-bracket">]</span></span>
<p>Andrew Gelman. The folk theorem of statistical computing. <a class="reference external" href="https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/">https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/</a>, 5 2008.</p>
</div>
<div class="citation" id="id15" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>114<span class="fn-bracket">]</span></span>
<p>John K Kruschke. Bayesian estimation supersedes the t test. <em>Journal of Experimental Psychology: General</em>, 142(2):573, 2013.</p>
</div>
<div class="citation" id="id32" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>115<span class="fn-bracket">]</span></span>
<p>Matthew PA. Clark and Brian D. Westerberg. How random is the toss of a coin? <em>Cmaj</em>, 181(12):E306–E308, 2009.</p>
</div>
<div class="citation" id="id155" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>116<span class="fn-bracket">]</span></span>
<p>James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs. 2018. URL: <a class="github reference external" href="http://github.com/google/jax">google/jax</a>.</p>
</div>
<div class="citation" id="id113" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>117<span class="fn-bracket">]</span></span>
<p>Wally R Gilks, Andrew Thomas, and David J Spiegelhalter. A language and program for complex bayesian modelling. <em>Journal of the Royal Statistical Society: Series D (The Statistician)</em>, 43(1):169–177, 1994.</p>
</div>
<div class="citation" id="id114" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>118<span class="fn-bracket">]</span></span>
<p>Bob Carpenter, Andrew Gelman, Matthew D Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. Stan: a probabilistic programming language. <em>Journal of statistical software</em>, 76(1):1–32, 2017.</p>
</div>
<div class="citation" id="id87" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>119<span class="fn-bracket">]</span></span>
<p>Maria I Gorinova, Andrew D Gordon, and Charles Sutton. Probabilistic programming with densities in slicstan: efficient, flexible, and deterministic. <em>Proceedings of the ACM on Programming Languages</em>, 3(POPL):1–30, 2019.</p>
</div>
<div class="citation" id="id165" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>120<span class="fn-bracket">]</span></span>
<p>Max Kochurov, Colin Carroll, Thomas Wiecki, and Junpeng Lao. Pymc4: exploiting coroutines for implementing a probabilistic programming framework. Program Transformations for ML Workshop at NeurIPS, 2019. URL: <a class="reference external" href="https://openreview.net/forum?id=rkgzj5Za8H">https://openreview.net/forum?id=rkgzj5Za8H</a>.</p>
</div>
<div class="citation" id="id142" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>121<span class="fn-bracket">]</span></span>
<p>George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan. Normalizing flows for probabilistic modeling and inference. <em>arXiv preprint arXiv:1912.02762</em>, 2019.</p>
</div>
<div class="citation" id="id89" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>122<span class="fn-bracket">]</span></span>
<p>Brandon T Willard. Minikanren as a tool for symbolic computation in python. <em>arXiv preprint arXiv:2005.11644</em>, 2020.</p>
</div>
<div class="citation" id="id136" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>123<span class="fn-bracket">]</span></span>
<p>Ohad Kammar, Sam Lindley, and Nicolas Oury. Handlers in action. <em>ACM SIGPLAN Notices</em>, 48(9):145–158, 2013.</p>
</div>
<div class="citation" id="id144" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>124<span class="fn-bracket">]</span></span>
<p>Frank Wood, Jan Willem Meent, and Vikash Mansinghka. A new approach to probabilistic programming inference. In <em>Artificial Intelligence and Statistics</em>, 1024–1032. PMLR, 2014.</p>
</div>
<div class="citation" id="id146" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>125<span class="fn-bracket">]</span></span>
<p>David Tolpin, Jan-Willem van de Meent, Hongseok Yang, and Frank Wood. Design and implementation of probabilistic programming language anglican. In <em>Proceedings of the 28th Symposium on the Implementation and Application of Functional programming Languages</em>, 1–12. 2016.</p>
</div>
<div class="citation" id="id137" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>126<span class="fn-bracket">]</span></span>
<p>Eli Bingham, Jonathan P Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D Goodman. Pyro: deep universal probabilistic programming. <em>The Journal of Machine Learning Research</em>, 20(1):973–978, 2019.</p>
</div>
<div class="citation" id="id138" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>127<span class="fn-bracket">]</span></span>
<p>Du Phan, Neeraj Pradhan, and Martin Jankowiak. Composable effects for flexible and accelerated probabilistic programming in numpyro. <em>arXiv preprint arXiv:1912.11554</em>, 2019.</p>
</div>
<div class="citation" id="id139" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>128<span class="fn-bracket">]</span></span>
<p>Dustin Tran, Matthew Hoffman, Dave Moore, Christopher Suter, Srinivas Vasudevan, Alexey Radul, Matthew Johnson, and Rif A Saurous. Simple, distributed, and accelerated probabilistic programming. <em>arXiv preprint arXiv:1811.02091</em>, 2018.</p>
</div>
<div class="citation" id="id140" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>129<span class="fn-bracket">]</span></span>
<p>Dave Moore and Maria I Gorinova. Effect handling for composable program transformations in edward2. <em>arXiv preprint arXiv:1811.06150</em>, 2018.</p>
</div>
<div class="citation" id="id176" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>130<span class="fn-bracket">]</span></span>
<p>Maria Gorinova, Dave Moore, and Matthew Hoffman. Automatic reparameterisation of probabilistic programs. In <em>International Conference on Machine Learning</em>, 3648–3657. PMLR, 2020.</p>
</div>
<div class="citation" id="id145" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>131<span class="fn-bracket">]</span></span>
<p>Jan-Willem van de Meent, Brooks Paige, Hongseok Yang, and Frank Wood. An introduction to probabilistic programming. <em>arXiv preprint arXiv:1809.10756</em>, 2018.</p>
</div>
<div class="citation" id="id92" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>132<span class="fn-bracket">]</span></span>
<p>Allen B. Downey. <em>Think Stats: Exploratory Data Analysis</em>. O'Reilly Media;, 2014.</p>
</div>
<div class="citation" id="id94" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>133<span class="fn-bracket">]</span></span>
<p>Peter H Westfall. Kurtosis as peakedness, 1905–2014. rip. <em>The American Statistician</em>, 68(3):191–195, 2014.</p>
</div>
<div class="citation" id="id17" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>134<span class="fn-bracket">]</span></span>
<p>T.M. Cover and J.A. Thomas. <em>Elements of Information Theory</em>. Wiley, 2012. ISBN 9781118585771.</p>
</div>
<div class="citation" id="id23" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>135<span class="fn-bracket">]</span></span>
<p>Hirotogu Akaike. Information theory and an extension of the maximum likelihood principle. In <em>Selected papers of hirotugu akaike</em>, pages 199–213. Springer, 1998.</p>
</div>
<div class="citation" id="id14" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>136<span class="fn-bracket">]</span></span>
<p>Sumio Watanabe and Manfred Opper. Asymptotic equivalence of bayes cross validation and widely applicable information criterion in singular learning theory. <em>Journal of machine learning research</em>, 2010.</p>
</div>
<div class="citation" id="id21" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>137<span class="fn-bracket">]</span></span>
<p>Aki Vehtari, Andrew Gelman, and Jonah Gabry. Practical bayesian model evaluation using leave-one-out cross-validation and waic. <em>Statistics and computing</em>, 27(5):1413–1432, 2017.</p>
</div>
<div class="citation" id="id24" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>138<span class="fn-bracket">]</span></span>
<p>W.R. Gilks, S. Richardson, and D. Spiegelhalter. <em>Markov Chain Monte Carlo in Practice</em>. Chapman &amp; Hall/CRC Interdisciplinary Statistics. CRC Press, 1995. ISBN 9781482214970.</p>
</div>
<div class="citation" id="id30" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>139<span class="fn-bracket">]</span></span>
<p>Nial Friel and Jason Wyse. Estimating the evidence–a review. <em>Statistica Neerlandica</em>, 66(3):288–308, 2012.</p>
</div>
<div class="citation" id="id29" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>140<span class="fn-bracket">]</span></span>
<p>Radford M Neal. Contribution to the discussion of “approximate bayesian inference with the weighted likelihood bootstrap” by michael a. newton and adrian e. raftery. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, 56:41–42, 1994.</p>
</div>
<div class="citation" id="id156" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>141<span class="fn-bracket">]</span></span>
<p>Quentin F Gronau, Alexandra Sarafoglou, Dora Matzke, Alexander Ly, Udo Boehm, Maarten Marsman, David S Leslie, Jonathan J Forster, Eric-Jan Wagenmakers, and Helen Steingroever. A tutorial on bridge sampling. <em>Journal of mathematical psychology</em>, 81:80–97, 2017.</p>
</div>
<div class="citation" id="id158" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>142<span class="fn-bracket">]</span></span>
<p>Danielle Navarro. A personal essay on bayes factors. <em>PsyArXiv</em>, 2020.</p>
</div>
<div class="citation" id="id157" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>143<span class="fn-bracket">]</span></span>
<p>Daniel J Schad, Bruno Nicenboim, Paul-Christian Bürkner, Michael Betancourt, and Shravan Vasishth. Workflow techniques for the robust use of bayes factors. <em>arXiv preprint arXiv:2103.08744</em>, 2021.</p>
</div>
<div class="citation" id="id154" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>144<span class="fn-bracket">]</span></span>
<p>E.A. Abbott and R. Jann. <em>Flatland: A Romance of Many Dimensions</em>. Oxford World's Classics. OUP Oxford, 2008. ISBN 9780199537501.</p>
</div>
<div class="citation" id="id116" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>145<span class="fn-bracket">]</span></span>
<p>Gael M Martin, David T Frazier, and Christian P Robert. Computing bayes: bayesian computation from 1763 to the 21st century. <em>arXiv preprint arXiv:2004.06425</em>, 2020.</p>
</div>
<div class="citation" id="id101" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>146<span class="fn-bracket">]</span></span>
<p>Heikki Haario, Eero Saksman, and Johanna Tamminen. An adaptive metropolis algorithm. <em>Bernoulli</em>, pages 223–242, 2001.</p>
</div>
<div class="citation" id="id104" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>147<span class="fn-bracket">]</span></span>
<p>Christophe Andrieu and Johannes Thoms. A tutorial on adaptive mcmc. <em>Statistics and computing</em>, 18(4):343–373, 2008.</p>
</div>
<div class="citation" id="id103" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>148<span class="fn-bracket">]</span></span>
<p>Gareth O Roberts and Jeffrey S Rosenthal. Examples of adaptive mcmc. <em>Journal of computational and graphical statistics</em>, 18(2):349–367, 2009.</p>
</div>
<div class="citation" id="id102" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>149<span class="fn-bracket">]</span></span>
<p>Dino Sejdinovic, Heiko Strathmann, Maria Lomeli Garcia, Christophe Andrieu, and Arthur Gretton. Kernel adaptive metropolis-hastings. In <em>International conference on machine learning</em>, 1665–1673. PMLR, 2014.</p>
</div>
<div class="citation" id="id105" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>150<span class="fn-bracket">]</span></span>
<p>Andrew Gelman, Walter R Gilks, and Gareth O Roberts. Weak convergence and optimal scaling of random walk metropolis algorithms. <em>The annals of applied probability</em>, 7(1):110–120, 1997.</p>
</div>
<div class="citation" id="id109" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>151<span class="fn-bracket">]</span></span>
<p>Gareth O Roberts and Jeffrey S Rosenthal. Optimal scaling for various metropolis-hastings algorithms. <em>Statistical science</em>, 16(4):351–367, 2001.</p>
</div>
<div class="citation" id="id110" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>152<span class="fn-bracket">]</span></span>
<p>Mylene Bedard. Optimal acceptance rates for metropolis algorithms: moving beyond 0.234. <em>Stochastic Processes and their Applications</em>, 118(12):2198–2222, 2008.</p>
</div>
<div class="citation" id="id111" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>153<span class="fn-bracket">]</span></span>
<p>Chris Sherlock. Optimal scaling of the random walk metropolis: general criteria for the 0.234 acceptance rule. <em>Journal of Applied Probability</em>, 50(1):1–15, 2013.</p>
</div>
<div class="citation" id="id112" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>154<span class="fn-bracket">]</span></span>
<p>Christopher CJ Potter and Robert H Swendsen. 0.234: the myth of a universal acceptance ratio for monte carlo simulations. <em>Physics Procedia</em>, 68:120–124, 2015.</p>
</div>
<div class="citation" id="id95" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>155<span class="fn-bracket">]</span></span>
<p>Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid monte carlo. <em>Physics letters B</em>, 195(2):216–222, 1987.</p>
</div>
<div class="citation" id="id96" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>156<span class="fn-bracket">]</span></span>
<p>S. Brooks, A. Gelman, G. Jones, and X.L. Meng. <em>Handbook of Markov Chain Monte Carlo</em>. Chapman &amp; Hall/CRC Handbooks of Modern Statistical Methods. CRC Press, 2011. ISBN 9781420079425.</p>
</div>
<div class="citation" id="id97" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>157<span class="fn-bracket">]</span></span>
<p>Michael Betancourt. A conceptual introduction to hamiltonian monte carlo. <em>arXiv preprint arXiv:1701.02434</em>, 2017.</p>
</div>
<div class="citation" id="id98" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>158<span class="fn-bracket">]</span></span>
<p>Matthew D Hoffman and Andrew Gelman. The no-u-turn sampler: adaptively setting path lengths in hamiltonian monte carlo. <em>Journal of Machine Learning Research</em>, 15(47):1593–1623, 2014.</p>
</div>
<div class="citation" id="id37" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>159<span class="fn-bracket">]</span></span>
<p>Pierre Del Moral, Arnaud Doucet, and Ajay Jasra. Sequential monte carlo samplers. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 68(3):411–436, 2006.</p>
</div>
<div class="citation" id="id36" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>160<span class="fn-bracket">]</span></span>
<p>Jianye Ching and Yi-Chu Chen. Transitional markov chain monte carlo method for bayesian model updating, model class selection, and model averaging. <em>Journal of engineering mechanics</em>, 133(7):816–832, 2007.</p>
</div>
<div class="citation" id="id35" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>161<span class="fn-bracket">]</span></span>
<p>Christian A Naesseth, Fredrik Lindsten, and Thomas B Schön. Elements of sequential monte carlo. <em>arXiv preprint arXiv:1903.04797</em>, 2019.</p>
</div>
<div class="citation" id="id162" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>162<span class="fn-bracket">]</span></span>
<p>Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Yes, but did it work?: evaluating variational inference. In <em>International Conference on Machine Learning</em>, 5581–5590. PMLR, 2018.</p>
</div>
<div class="citation" id="id159" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>163<span class="fn-bracket">]</span></span>
<p>David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational inference: a review for statisticians. <em>Journal of the American statistical Association</em>, 112(518):859–877, 2017.</p>
</div>
<div class="citation" id="id163" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>164<span class="fn-bracket">]</span></span>
<p>Alp Kucukelbir, Dustin Tran, Rajesh Ranganath, Andrew Gelman, and David M. Blei. Automatic differentiation variational inference. <em>The Journal of Machine Learning Research</em>, 18(1):430–474, 2017.</p>
</div>
<div class="citation" id="id93" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>165<span class="fn-bracket">]</span></span>
<p>J.K. Kruschke. <em>Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan</em>. Academic Press. Academic Press, 2015. ISBN 9780124058880.</p>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./markdown"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="glossary.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">12. </span>Glossary</p>
      </div>
    </a>
    <a class="right-next"
       href="../notebooks/chp_01.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Code 1: Bayesian Inference</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Martin, Kumar, Lao
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>