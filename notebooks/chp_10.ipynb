{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code 10: Probabilistic Programming Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} This is a reference notebook for the book Bayesian Modeling and Computation in Python\n",
    ":class: tip, dropdown\n",
    "The textbook is not needed to use or run this code, though the context and explanation is missing from this notebook.\n",
    "\n",
    "If you'd like a copy it's available\n",
    "[from the CRC Press](https://www.routledge.com/Bayesian-Modeling-and-Computation-in-Python/Martin-Kumar-Lao/p/book/9780367894368)\n",
    "or from [Amazon](https://www.routledge.com/Bayesian-Modeling-and-Computation-in-Python/Martin-Kumar-Lao/p/book/9780367894368).\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run 2021-11-19 16:52:42.074557\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "import datetime\n",
    "print(f\"Last Run {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use(\"arviz-grayscale\")\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "\n",
    "simple_grad = grad(lambda x: x**2)\n",
    "print(simple_grad(4.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_p_val: -6.697315216064453\n",
      "grad: 2.4000000953674316\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "from jax.scipy.stats import norm\n",
    "\n",
    "def model(test_point, observed):\n",
    "    z_pdf = norm.logpdf(test_point, loc=0, scale=5)\n",
    "    x_pdf = norm.logpdf(observed, loc=test_point, scale=1)\n",
    "    logpdf = z_pdf + x_pdf\n",
    "    return logpdf\n",
    "\n",
    "model_grad = grad(model)\n",
    "\n",
    "observed, test_point = 5.0, 2.5 \n",
    "logp_val = model(test_point, observed)\n",
    "grad = model_grad(test_point, observed)\n",
    "print(f\"log_p_val: {logp_val}\")\n",
    "print(f\"grad: {grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(-6.69731498), array([2.4])]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    z = pm.Normal(\"z\", 0., 5.)\n",
    "    x = pm.Normal(\"x\", mu=z, sd=1., observed=observed)\n",
    "\n",
    "func = model.logp_dlogp_function()\n",
    "func.set_extra_values({})\n",
    "print(func(np.array([test_point])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 ns ± 6.11 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def fraud_detector(fraud_observations, non_fraud_observations, fraud_prior=8, non_fraud_prior=6):\n",
    "    \"\"\"Conjugate Beta Binomial model for fraud detection\"\"\"\n",
    "    expectation = (fraud_prior + fraud_observations) / (\n",
    "        fraud_prior + fraud_observations + non_fraud_prior + non_fraud_observations)\n",
    "    \n",
    "    if expectation > .5:\n",
    "        return {\"suspend_card\":True}\n",
    "\n",
    "%timeit fraud_detector(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPL Driven Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0029150244650281948"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = np.repeat(2, 2)\n",
    "pdf = stats.norm(0, 1).pdf(observed)\n",
    "np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = np.repeat(2, 1000)\n",
    "pdf = stats.norm(0, 1).pdf(observed)\n",
    "np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999996"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05399096651318806, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[0], np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.9189385332046727, -2.9189385332046727, -2918.9385332046736)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logpdf = stats.norm(0, 1).logpdf(observed)\n",
    "np.log(pdf[0]), logpdf[0], logpdf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9189385332046727"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(pdf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original domain: [-1.   -0.25  0.5   1.25  2.  ]\n",
      "Transformed domain: [       -inf -1.09861229  0.          1.09861229         inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/srk5qjp563l5f9mrjtp44bh800jqsw/T/ipykernel_3646/2568761612.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  transform = np.log(domain - lower) - np.log(upper - domain)\n"
     ]
    }
   ],
   "source": [
    "lower, upper = -1, 2\n",
    "domain = np.linspace(lower, upper, 5)\n",
    "transform = np.log(domain - lower) - np.log(upper - domain)\n",
    "print(f\"Original domain: {domain}\")\n",
    "print(f\"Transformed domain: {transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x_interval__ ~ TransformedDistribution]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    x = pm.Uniform(\"x\", -1., 2.)\n",
    "    \n",
    "model.vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.2538560220859454 -1.0986122886681098\n",
      "-1.6265233750364456 -1.0986122886681098\n"
     ]
    }
   ],
   "source": [
    "print(model.logp({\"x_interval__\":-2}),\n",
    "      model.logp_nojac({\"x_interval__\":-2}))\n",
    "print(model.logp({\"x_interval__\":1}),\n",
    "      model.logp_nojac({\"x_interval__\":1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfb = tfp.bijectors\n",
    "\n",
    "lognormal0 = tfd.LogNormal(0., 1.)\n",
    "lognormal1 = tfd.TransformedDistribution(tfd.Normal(0., 1.), tfb.Exp())\n",
    "x = lognormal0.sample(100)\n",
    "\n",
    "np.testing.assert_array_equal(lognormal0.log_prob(x), lognormal1.log_prob(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/srk5qjp563l5f9mrjtp44bh800jqsw/T/ipykernel_3646/2626254216.py:6: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace_transform = pm.sample(chains=1, draws=100000)\n",
      "Auto-assigning NUTS sampler...\n",
      "INFO:pymc3:Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "INFO:pymc3:Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "INFO:pymc3:Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [sd]\n",
      "INFO:pymc3:NUTS: [sd]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='101000' class='' max='101000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [101000/101000 00:33<00:00 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 1_000 tune and 100_000 draw iterations (1_000 + 100_000 draws total) took 34 seconds.\n",
      "INFO:pymc3:Sampling 1 chain for 1_000 tune and 100_000 draw iterations (1_000 + 100_000 draws total) took 34 seconds.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "INFO:pymc3:Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sd_log__ ~ TransformedDistribution]\n",
      "Diverging: 0\n"
     ]
    }
   ],
   "source": [
    "y_observed = stats.norm(0, .01).rvs(20)\n",
    "\n",
    "with pm.Model() as model_transform:\n",
    "    sd = pm.HalfNormal(\"sd\", 5)\n",
    "    y = pm.Normal(\"y\", mu=0, sigma=sd, observed=y_observed)\n",
    "    trace_transform = pm.sample(chains=1, draws=100000)\n",
    "\n",
    "print(model_transform.vars)\n",
    "print(f\"Diverging: {trace_transform.get_sampler_stats('diverging').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/srk5qjp563l5f9mrjtp44bh800jqsw/T/ipykernel_3646/2939584159.py:4: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  trace_no_transform = pm.sample(chains=1, draws=100000)\n",
      "Auto-assigning NUTS sampler...\n",
      "INFO:pymc3:Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "INFO:pymc3:Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "INFO:pymc3:Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [sd]\n",
      "INFO:pymc3:NUTS: [sd]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='101000' class='' max='101000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [101000/101000 00:33<00:00 Sampling chain 0, 17 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 1_000 tune and 100_000 draw iterations (1_000 + 100_000 draws total) took 34 seconds.\n",
      "INFO:pymc3:Sampling 1 chain for 1_000 tune and 100_000 draw iterations (1_000 + 100_000 draws total) took 34 seconds.\n",
      "There were 17 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc3:There were 17 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "INFO:pymc3:Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sd ~ HalfNormal]\n",
      "Diverging: 17\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model_no_transform:\n",
    "    sd = pm.HalfNormal(\"sd\", 5, transform=None)\n",
    "    y = pm.Normal(\"y\", mu=0, sigma=sd, observed=y_observed)\n",
    "    trace_no_transform = pm.sample(chains=1, draws=100000)\n",
    "\n",
    "print(model_no_transform.vars)\n",
    "print(f\"Diverging: {trace_no_transform.get_sampler_stats('diverging').sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation Graphs and Automatic Reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 3\n",
    "y = 1\n",
    "x * y / x + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "theano.config.compute_test_value = 'ignore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{add,no_inplace} [id A] ''   \n",
      " |Elemwise{mul,no_inplace} [id B] ''   \n",
      " | |x [id C]\n",
      " | |Elemwise{true_div,no_inplace} [id D] ''   \n",
      " |   |y [id E]\n",
      " |   |x [id C]\n",
      " |InplaceDimShuffle{x} [id F] ''   \n",
      "   |TensorConstant{0} [id G]\n"
     ]
    }
   ],
   "source": [
    "x = theano.tensor.vector(\"x\")\n",
    "y = theano.tensor.vector(\"y\")\n",
    "out = x*(y/x) + 0\n",
    "theano.printing.debugprint(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepCopyOp [id A] 'y'   0\n",
      " |y [id B]\n"
     ]
    }
   ],
   "source": [
    "fgraph = theano.function([x,y], [out])\n",
    "theano.printing.debugprint(fgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3.])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgraph([1],[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 10.1 and Figure 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file is available at img/chp10/symbolic_graph_unopt.png\n",
      "The output file is available at img/chp10/symbolic_graph_opt.png\n"
     ]
    }
   ],
   "source": [
    "theano.printing.pydotprint(\n",
    "    out, outfile=\"img/chp10/symbolic_graph_unopt.png\",\n",
    "    var_with_name_simple=False, high_contrast=False, with_ids=True)\n",
    "theano.printing.pydotprint(\n",
    "    fgraph, \n",
    "    outfile=\"img/chp10/symbolic_graph_opt.png\", \n",
    "    var_with_name_simple=False, high_contrast=False, with_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum{acc_dtype=float64} [id A] '__logp'   \n",
      " |MakeVector{dtype='float64'} [id B] ''   \n",
      "   |Sum{acc_dtype=float64} [id C] ''   \n",
      "     |Sum{acc_dtype=float64} [id D] '__logp_x'   \n",
      "       |Elemwise{switch,no_inplace} [id E] ''   \n",
      "         |Elemwise{mul,no_inplace} [id F] ''   \n",
      "         | |TensorConstant{1} [id G]\n",
      "         | |Elemwise{mul,no_inplace} [id H] ''   \n",
      "         |   |TensorConstant{1} [id I]\n",
      "         |   |Elemwise{gt,no_inplace} [id J] ''   \n",
      "         |     |TensorConstant{1.0} [id K]\n",
      "         |     |TensorConstant{0} [id L]\n",
      "         |Elemwise{true_div,no_inplace} [id M] ''   \n",
      "         | |Elemwise{add,no_inplace} [id N] ''   \n",
      "         | | |Elemwise{mul,no_inplace} [id O] ''   \n",
      "         | | | |Elemwise{neg,no_inplace} [id P] ''   \n",
      "         | | | | |TensorConstant{1.0} [id Q]\n",
      "         | | | |Elemwise{pow,no_inplace} [id R] ''   \n",
      "         | | |   |Elemwise{sub,no_inplace} [id S] ''   \n",
      "         | | |   | |x ~ Normal [id T]\n",
      "         | | |   | |TensorConstant{0.0} [id U]\n",
      "         | | |   |TensorConstant{2} [id V]\n",
      "         | | |Elemwise{log,no_inplace} [id W] ''   \n",
      "         | |   |Elemwise{true_div,no_inplace} [id X] ''   \n",
      "         | |     |Elemwise{true_div,no_inplace} [id Y] ''   \n",
      "         | |     | |TensorConstant{1.0} [id Q]\n",
      "         | |     | |TensorConstant{3.141592653589793} [id Z]\n",
      "         | |     |TensorConstant{2.0} [id BA]\n",
      "         | |TensorConstant{2.0} [id BB]\n",
      "         |TensorConstant{-inf} [id BC]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model_normal:\n",
    "    x = pm.Normal(\"x\", 0., 1.)\n",
    "    \n",
    "theano.printing.debugprint(model_normal.logpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpyro\n",
    "from tensorflow_probability.substrates import jax as tfp_jax\n",
    "\n",
    "tfp_dist = tfp_jax.distributions\n",
    "numpyro_dist = numpyro.distributions\n",
    "\n",
    "root = tfp_dist.JointDistributionCoroutine.Root\n",
    "def tfp_model():\n",
    "    x = yield root(tfp_dist.Normal(loc=1.0, scale=2.0, name=\"x\"))\n",
    "    z = yield root(tfp_dist.HalfNormal(scale=1., name=\"z\"))\n",
    "    y = yield tfp_dist.Normal(loc=x, scale=z, name=\"y\")\n",
    "    \n",
    "def numpyro_model():\n",
    "    x = numpyro.sample(\"x\", numpyro_dist.Normal(loc=1.0, scale=2.0))\n",
    "    z = numpyro.sample(\"z\", numpyro_dist.HalfNormal(scale=1.0))\n",
    "    y = numpyro.sample(\"y\", numpyro_dist.Normal(loc=x, scale=z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object tfp_model at 0x7fec68bafac0>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(tfp_model())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(numpyro_model())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = jax.random.PRNGKey(52346)\n",
    "\n",
    "# Draw samples\n",
    "jd = tfp_dist.JointDistributionCoroutine(tfp_model)\n",
    "tfp_sample = jd.sample(1, seed=sample_key)\n",
    "\n",
    "predictive = numpyro.infer.Predictive(numpyro_model, num_samples=1)\n",
    "numpyro_sample = predictive(sample_key)\n",
    "\n",
    "# Evaluate log prob\n",
    "log_likelihood_tfp = jd.log_prob(tfp_sample)\n",
    "log_likelihood_numpyro = numpyro.infer.util.log_density(\n",
    "    numpyro_model, [], {},\n",
    "    # Samples returning from JointDistributionCoroutine is a\n",
    "    # Namedtuple like Python object, we convert it to a dictionary\n",
    "    # so that numpyro can recognize it.\n",
    "    params=tfp_sample._asdict())\n",
    "\n",
    "# Validate that we get the same log prob\n",
    "np.testing.assert_allclose(log_likelihood_tfp, log_likelihood_numpyro[0], rtol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  x=DeviceArray(0.42507368, dtype=float32),\n",
       "  z=DeviceArray(0.01, dtype=float32),\n",
       "  y=DeviceArray(0.42213476, dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condition z to .01 in TFP and sample\n",
    "jd.sample(z=.01, seed=sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': DeviceArray([1.1232405], dtype=float32),\n",
       " 'y': DeviceArray([1.1318897], dtype=float32),\n",
       " 'z': array([0.01])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condition z to .01 in NumPyro and sample\n",
    "predictive = numpyro.infer.Predictive(\n",
    "    numpyro_model, num_samples=1, params={\"z\": np.asarray(.01)})\n",
    "predictive(sample_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditioned z to .01 in TFP and construct conditional distributions\n",
    "dist, value = jd.sample_distributions(z=.01, seed=sample_key)\n",
    "assert dist.y.loc == value.x\n",
    "assert dist.y.scale == value.z\n",
    "\n",
    "# Conditioned z to .01 in NumPyro and construct conditional distributions\n",
    "model = numpyro.handlers.substitute(numpyro_model, data={\"z\": .01})\n",
    "with numpyro.handlers.seed(rng_seed=sample_key):\n",
    "    # Under the seed context, the default behavior of a NumPyro model is the\n",
    "    # same as in Pyro: drawing prior sample.\n",
    "    model_trace = numpyro.handlers.trace(numpyro_model).get_trace()\n",
    "assert model_trace[\"y\"][\"fn\"].loc == model_trace[\"x\"][\"value\"]\n",
    "assert model_trace[\"y\"][\"fn\"].scale == model_trace[\"z\"][\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a PPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Draw 2 samples from a Normal(1., 2.) distribution\n",
    "x = stats.norm.rvs(loc=1.0, scale=2.0, size=2, random_state=1234)\n",
    "# Evaluate the log probability of the samples \n",
    "logp = stats.norm.logpdf(x, loc=1.0, scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_variable_x = stats.norm(loc=1.0, scale=2.0)\n",
    "\n",
    "x = random_variable_x.rvs(size=2, random_state=1234)\n",
    "logp = random_variable_x.logpdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'rv_frozen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7p/srk5qjp563l5f9mrjtp44bh800jqsw/T/ipykernel_3646/2580115495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/bmcp/lib/python3.9/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, size, random_state)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'random_state'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/bmcp/lib/python3.9/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   1092\u001b[0m             \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# do not forget to restore the _random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'rv_frozen'"
     ]
    }
   ],
   "source": [
    "x = stats.norm(loc=1.0, scale=2.0)\n",
    "y = stats.norm(loc=x, scale=0.1)\n",
    "y.rvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1571257036684732\n",
      "0.5129008281470354\n",
      "-0.2750327073812393\n",
      "-0.1797237136258827\n",
      "-2.7978765955524114\n"
     ]
    }
   ],
   "source": [
    "class RandomVariable:\n",
    "    def __init__(self, distribution):\n",
    "        self.distribution = distribution\n",
    "\n",
    "    def __array__(self):\n",
    "        return np.asarray(self.distribution.rvs())\n",
    "\n",
    "x = RandomVariable(stats.norm(loc=1.0, scale=2.0))\n",
    "z = RandomVariable(stats.halfnorm(loc=0., scale=1.))\n",
    "y = RandomVariable(stats.norm(loc=x, scale=z))\n",
    "\n",
    "for i in range(5):\n",
    "    print(np.asarray(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomVariable:\n",
    "    def __init__(self, distribution, value=None):\n",
    "        self.distribution = distribution\n",
    "        self.set_value(value)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(value={self.__array__()})\"\n",
    "\n",
    "    def __array__(self, dtype=None):\n",
    "        if self.value is None:\n",
    "            return np.asarray(self.distribution.rvs(), dtype=dtype)\n",
    "        return self.value\n",
    "\n",
    "    def set_value(self, value=None):\n",
    "        self.value = value\n",
    "    \n",
    "    def log_prob(self, value=None):\n",
    "        if value is not None:\n",
    "            self.set_value(value)\n",
    "        return self.distribution.logpdf(np.array(self))\n",
    "\n",
    "x = RandomVariable(stats.norm(loc=1.0, scale=2.0))\n",
    "z = RandomVariable(stats.halfnorm(loc=0., scale=1.))\n",
    "y = RandomVariable(stats.norm(loc=x, scale=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomVariable(value=2.113889264473519)\n",
      "RandomVariable(value=-0.9153866580169316)\n",
      "RandomVariable(value=2.7839356392110224)\n",
      "  Set x=5 and z=0.1\n",
      "RandomVariable(value=4.971704202268103)\n",
      "RandomVariable(value=4.925771989212217)\n",
      "RandomVariable(value=5.024323806499401)\n",
      "  Reset z\n",
      "RandomVariable(value=4.732558936959928)\n",
      "RandomVariable(value=4.998079910235703)\n",
      "RandomVariable(value=4.905656937449344)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(y)\n",
    "\n",
    "print(f\"  Set x=5 and z=0.1\")\n",
    "x.set_value(np.asarray(5))\n",
    "z.set_value(np.asarray(0.05))\n",
    "for i in range(3):\n",
    "    print(y)\n",
    "\n",
    "print(f\"  Reset z\")\n",
    "z.set_value(None)\n",
    "for i in range(3):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.881815599614018"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observed y = 5.\n",
    "y.set_value(np.array(5.))\n",
    "\n",
    "posterior_density = lambda xval, zval: x.log_prob(xval) + z.log_prob(zval) + \\\n",
    "                y.log_prob()\n",
    "posterior_density(np.array(0.), np.array(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15.881815599614018"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_prob(xval, zval, yval=5):\n",
    "    x_dist = stats.norm(loc=1.0, scale=2.0)\n",
    "    z_dist = stats.halfnorm(loc=0., scale=1.)\n",
    "    y_dist = stats.norm(loc=xval, scale=zval)\n",
    "    return x_dist.logpdf(xval) + z_dist.logpdf(zval) + y_dist.logpdf(yval)\n",
    "\n",
    "log_prob(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.6274777874169912, 0.9358428814217807, 0.029987051428045586)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prior_sample():\n",
    "    x = stats.norm(loc=1.0, scale=2.0).rvs()\n",
    "    z = stats.halfnorm(loc=0., scale=1.).rvs()\n",
    "    y = stats.norm(loc=x, scale=z).rvs()\n",
    "    return x, z, y\n",
    "\n",
    "prior_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2,), (2,), (2,)]\n",
      "[(2, 3, 5), (2, 3, 5), (2, 3, 5)]\n"
     ]
    }
   ],
   "source": [
    "def prior_sample(size):\n",
    "    x = stats.norm(loc=1.0, scale=2.0).rvs(size=size)\n",
    "    z = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "    y = stats.norm(loc=x, scale=z).rvs()\n",
    "    return x, z, y\n",
    "\n",
    "print([x.shape for x in prior_sample(size=(2))])\n",
    "print([x.shape for x in prior_sample(size=(2, 3, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_feature = 1000, 5\n",
    "X = np.random.randn(n_row, n_feature)\n",
    "\n",
    "def lm_prior_sample0():\n",
    "    intercept = stats.norm(loc=0, scale=10.0).rvs()\n",
    "    beta = stats.norm(loc=np.zeros(n_feature), scale=10.0).rvs()\n",
    "    sigma = stats.halfnorm(loc=0., scale=1.).rvs()\n",
    "    y_hat = X @ beta + intercept\n",
    "    y = stats.norm(loc=y_hat, scale=sigma).rvs()\n",
    "    return intercept, beta, sigma, y\n",
    "\n",
    "def lm_prior_sample(size=10):\n",
    "    if isinstance(size, int):\n",
    "        size = (size,)\n",
    "    else:\n",
    "        size = tuple(size)\n",
    "    intercept = stats.norm(loc=0, scale=10.0).rvs(size=size)\n",
    "    beta = stats.norm(loc=np.zeros(n_feature), scale=10.0).rvs(\n",
    "        size=size + (n_feature,))\n",
    "    sigma = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "    y_hat = np.squeeze(X @ beta[..., None]) + intercept[..., None]\n",
    "    y = stats.norm(loc=y_hat, scale=sigma[..., None]).rvs()\n",
    "    return intercept, beta, sigma, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), (5,), (), (1000,)]\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in lm_prior_sample0()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), (5,), (), (1000,)]\n",
      "[(10,), (10, 5), (10,), (10, 1000)]\n",
      "[(10, 3), (10, 3, 5), (10, 3), (10, 3, 1000)]\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in lm_prior_sample(size=())])\n",
    "print([x.shape for x in lm_prior_sample(size=10)])\n",
    "print([x.shape for x in lm_prior_sample(size=[10, 3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lm_prior_sample2(size=10):\n",
    "#     intercept = stats.norm(loc=0, scale=10.0).rvs(size=size)\n",
    "#     beta = stats.multivariate_normal(\n",
    "#         mean=np.zeros(n_feature), cov=10.0).rvs(size=size)\n",
    "#     sigma = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "#     y_hat = np.einsum('ij,...j->...i', X, beta) + intercept[..., None]\n",
    "#     y = stats.norm(loc=y_hat, scale=sigma[..., None]).rvs()\n",
    "#     return intercept, beta, sigma, y\n",
    "\n",
    "# print([x.shape for x in lm_prior_sample2(size=())])\n",
    "# print([x.shape for x in lm_prior_sample2(size=10)])\n",
    "# print([x.shape for x in lm_prior_sample2(size=(10, 3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 10.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.JointDistributionSequential(\"JointDistributionSequential\", batch_shape=[[], [], [], []], event_shape=[[], [5], [], [1000]], dtype=[float32, float32, float32, float32])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "jd = tfd.JointDistributionSequential([\n",
    "    tfd.Normal(0, 10),\n",
    "    tfd.Sample(tfd.Normal(0, 10), n_feature),\n",
    "    tfd.HalfNormal(1),\n",
    "    lambda sigma, beta, intercept: tfd.Independent(\n",
    "        tfd.Normal(\n",
    "            loc=tf.einsum(\"ij,...j->...i\", X, beta) + intercept[..., None],\n",
    "            scale=sigma[..., None]),\n",
    "        reinterpreted_batch_ndims=1,\n",
    "        name=\"y\")\n",
    "])\n",
    "\n",
    "print(jd)\n",
    "\n",
    "n_sample = [3, 2]\n",
    "for log_prob_part in jd.log_prob_parts(jd.sample(n_sample)):\n",
    "    assert log_prob_part.shape == n_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
