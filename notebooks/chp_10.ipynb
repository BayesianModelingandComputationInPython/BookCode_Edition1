{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Programming Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "az.style.use(\"arviz-grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(8., dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import grad\n",
    "from jax.scipy import stats\n",
    "\n",
    "simple_grad = grad(lambda x: x**2)\n",
    "simple_grad(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_p_val: -6.697315216064453\n",
      "grad: 2.4000000953674316\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "from jax.scipy import stats\n",
    "\n",
    "def model(test_point, observed):\n",
    "    z_pdf = stats.norm.logpdf(test_point, loc=0, scale=5)\n",
    "    x_pdf = stats.norm.logpdf(observed, loc=test_point, scale=1)\n",
    "    logpdf = z_pdf + x_pdf\n",
    "    return logpdf\n",
    "\n",
    "model_grad = grad(model)\n",
    "\n",
    "observed, test_point = 5.0, 2.5 \n",
    "logp_val = model(test_point, observed)\n",
    "grad = model_grad(test_point, observed)\n",
    "print(f\"log_p_val: {logp_val}\")\n",
    "print(f\"grad: {grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(-6.69731498), array([2.4])]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    z = pm.Normal(\"z\", 0., 5.)\n",
    "    x = pm.Normal(\"x\", mu=z, sd=1., observed=observed)\n",
    "\n",
    "func = model.logp_dlogp_function()\n",
    "func.set_extra_values({})\n",
    "print(func(np.array([test_point])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 ns ± 0.647 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def fraud_detector(obs_fraud, obs_non_fraud, fraud_prior=8, non_fraud_prior=6):\n",
    "    \"\"\"Conjugate beta binomial model for fraud detection\"\"\"\n",
    "    \n",
    "    alpha_post = fraud_prior + observed_fraud\n",
    "    beta_post = fraud_prior + observed_fraud + non_fraud_prior + obs_non_fraud\n",
    "    expectation = alpha_post / (alpha_post + beta_post)\n",
    "    \n",
    "    if expectation > .5:\n",
    "        return {\"suspend_card\":True}\n",
    "\n",
    "%timeit fraud_detector(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0029150244650281948"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = np.repeat(2, 2)\n",
    "pdf = stats.norm(0,1).pdf(observed)\n",
    "np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = np.repeat(2, 1000)\n",
    "pdf = stats.norm(0,1).pdf(observed)\n",
    "np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05399096651318806, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[0], np.prod(pdf, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.9189385332046727, -2.9189385332046727, -2918.9385332046736)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logpdf = stats.norm(0,1).logpdf(observed)\n",
    "np.log(pdf[0]), logpdf[0], logpdf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9189385332046727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(pdf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower, upper = -1, 2\n",
    "domain = np.linspace(lower, upper, 5)\n",
    "transform = np.log(domain - lower) - np.log(upper - domain)\n",
    "print(f\"Original domain: {domain}\")\n",
    "print(f\"Transformed domain: {transform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_transform:\n",
    "    x = pm.Uniform(\"x\", -1., 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transform.vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_transform.logp({\"x_interval__\":-2})), \n",
    "print(model_transform.logp({\"x_interval__\":1}))\n",
    "print(model_transform.logp_nojac ({\"x_interval__\":-2}))\n",
    "print(model_transform.logp_nojac ({\"x_interval__\":1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_transform.logp({\"x_interval__\":-2}),\n",
    "        model_transform.logp_nojac({\"x_interval__\":-2}))\n",
    "print(model_transform.logp({\"x_interval__\":1}),\n",
    "          model_transform.logp_nojac({\"x_interval__\":1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "y_observed = stats.norm(0, .01).rvs(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_transform:\n",
    "    sd = pm.HalfNormal(\"sd\", 5)\n",
    "    y = pm.Normal(\"y\", mu=0, sd=sd, observed=y_observed)\n",
    "    trace_transform = pm.sample(chains=1, draws=100000, random_seed=0)\n",
    "model.vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transform.vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Diverging: {trace_transform.get_sampler_stats(\"diverging\").sum()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace_transform, combined=True, divergences=\"bottom\", kind=\"rank_bars\")\n",
    "plt.savefig(\"img/model_transformed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    sd = pm.HalfNormal(\"sd\", 5, transform=None)\n",
    "    y = pm.Normal(\"y\", mu=0, sd=sd, observed=y_observed)\n",
    "    trace_no_transform = pm.sample(chains=1, draws=100000, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_transform.get_sampler_stats(\"diverging\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace_no_transform, combined=True, divergences=\"bottom\", kind=\"rank_bars\")\n",
    "plt.savefig(\"img/model_not_transformed.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=3\n",
    "y=1\n",
    "x*y/x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theano.config.compute_test_value = 'ignore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = theano.tensor.vector(\"x\")\n",
    "y = theano.tensor.vector(\"y\")\n",
    "out = x*(y/x) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theano.printing.debugprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgraph = theano.function([x,y], [out])\n",
    "theano.printing.debugprint(fgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgraph([1],[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theano.printing.pydotprint(out, outfile=\"img/symbolic_graph_unopt.png\", var_with_name_simple=False, high_contrast=False, with_ids=True)\n",
    "theano.printing.pydotprint(fgraph, outfile=\"img/symbolic_graph_opt.png\", var_with_name_simple=False, high_contrast=False, with_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_normal:\n",
    "    x = pm.Normal(\"x\", 0., 1.)\n",
    "    \n",
    "theano.printing.debugprint(model_normal.logpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPL from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw 2 samples from a Normal(1., 2.) distribution\n",
    "x = stats.norm.rvs(loc=1.0, scale=2.0, size=2, random_state=1234)\n",
    "# Evaluate the log probability of the samples \n",
    "logp = stats.norm.logpdf(x, loc=1.0, scale=2.0)\n",
    "\n",
    "print(x, logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_variable_x = stats.norm(loc=1.0, scale=2.0)\n",
    "\n",
    "x = random_variable_x.rvs(size=2, random_state=1234)\n",
    "logp = random_variable_x.logpdf(x)\n",
    "\n",
    "print(x, logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stats.norm(loc=1.0, scale=2.0)\n",
    "y = stats.norm(loc=x, scale=1.)\n",
    "# y.rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomVariable:\n",
    "    def __init__(self, distribution):\n",
    "        self.distribution = distribution\n",
    "\n",
    "    def __array__(self):\n",
    "        return np.asarray(self.distribution.rvs())\n",
    "\n",
    "x = RandomVariable(stats.norm(loc=1.0, scale=2.0))\n",
    "z = RandomVariable(stats.halfnorm(loc=0., scale=1.))\n",
    "y = RandomVariable(stats.norm(loc=x, scale=z))\n",
    "\n",
    "for i in range(5):\n",
    "    print(np.asarray(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomVariable:\n",
    "    def __init__(self, distribution, **kwargs):\n",
    "        self.distribution = distribution\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def __array__(self):\n",
    "        return np.asarray(self.distribution(**self.kwargs).rvs())\n",
    "\n",
    "x = RandomVariable(stats.norm, loc=1.0, scale=2.0)\n",
    "y = RandomVariable(stats.norm, loc=x, scale=1.)\n",
    "np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomVariable:\n",
    "    def __init__(self, distribution, value=None):\n",
    "        self.distribution = distribution\n",
    "        self.set_value(value)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(value={self.__array__()})\"\n",
    "\n",
    "    def __array__(self, dtype=None):\n",
    "        if self.value is None:\n",
    "            return np.asarray(self.distribution.rvs(), dtype=dtype)\n",
    "        return self.value\n",
    "\n",
    "    def set_value(self, value=None):\n",
    "        self.value = value\n",
    "    \n",
    "    def log_prob(self, value=None):\n",
    "        if value is not None:\n",
    "            self.set_value(value)\n",
    "        return self.distribution.logpdf(np.array(self))\n",
    "\n",
    "x = RandomVariable(stats.norm(loc=1.0, scale=2.0))\n",
    "z = RandomVariable(stats.halfnorm(loc=0., scale=1.))\n",
    "y = RandomVariable(stats.norm(loc=x, scale=z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(y)\n",
    "\n",
    "print(f\"  Set x=5 and z=0.1\")\n",
    "x.set_value(np.asarray(5))\n",
    "z.set_value(np.asarray(0.05))\n",
    "for i in range(3):\n",
    "    print(y)\n",
    "\n",
    "print(f\"  Reset z\")\n",
    "z.set_value(None)\n",
    "for i in range(3):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.set_value(np.array(5.))\n",
    "z.set_value(np.array(3.))\n",
    "x.log_prob() + z.log_prob() + y.log_prob(np.array(5.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed y = 5.\n",
    "y.set_value(np.array(5.))\n",
    "\n",
    "posterior_density = lambda xval, zval: x.log_prob(xval) + z.log_prob(zval) + y.log_prob()\n",
    "posterior_density(np.array(0.), np.array(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(xval, zval, yval=5):\n",
    "    x_dist = stats.norm(loc=1.0, scale=2.0)\n",
    "    z_dist = stats.halfnorm(loc=0., scale=1.)\n",
    "    y_dist = stats.norm(loc=xval, scale=zval)\n",
    "    return x_dist.logpdf(xval) + z_dist.logpdf(zval) + y_dist.logpdf(yval)\n",
    "\n",
    "log_prob(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval, zval = 10, 5\n",
    "posterior_density(np.array(xval), np.array(zval)), log_prob(xval, zval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_sample():\n",
    "    x = stats.norm(loc=1.0, scale=2.0).rvs()\n",
    "    z = stats.halfnorm(loc=0., scale=1.).rvs()\n",
    "    y = stats.norm(loc=x, scale=z).rvs()\n",
    "    return x, z, y\n",
    "\n",
    "prior_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_sample(size):\n",
    "    x = stats.norm(loc=1.0, scale=2.0).rvs(size=size)\n",
    "    z = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "    y = stats.norm(loc=x, scale=z).rvs()\n",
    "    return x, z, y\n",
    "\n",
    "print([x.shape for x in prior_sample(size=(2))])\n",
    "print([x.shape for x in prior_sample(size=(2, 3, 5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_feature = 1000, 5\n",
    "X = np.random.randn(n_row, n_feature)\n",
    "\n",
    "def lm_prior_sample0():\n",
    "    intercept = stats.norm(loc=0, scale=10.0).rvs()\n",
    "    beta = stats.norm(loc=np.zeros(n_feature), scale=10.0).rvs()\n",
    "    sigma = stats.halfnorm(loc=0., scale=1.).rvs()\n",
    "    y_hat = X @ beta + intercept\n",
    "    y = stats.norm(loc=y_hat, scale=sigma).rvs()\n",
    "    return intercept, beta, sigma, y\n",
    "\n",
    "print([x.shape for x in lm_prior_sample0()])\n",
    "\n",
    "def lm_prior_sample(size=10):\n",
    "    if isinstance(size, int):\n",
    "        size = (size,)\n",
    "    else:\n",
    "        size = tuple(size)\n",
    "    intercept = stats.norm(loc=0, scale=10.0).rvs(size=size)\n",
    "    beta = stats.norm(loc=np.zeros(n_feature), scale=10.0).rvs(\n",
    "        size=size + (n_feature,))\n",
    "    sigma = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "    y_hat = np.squeeze(X @ beta[..., None]) + intercept[..., None]\n",
    "#     y_hat = np.einsum('ij,...j->...i', X, beta) + intercept[..., None]\n",
    "    y = stats.norm(loc=y_hat, scale=sigma[..., None]).rvs()\n",
    "    return intercept, beta, sigma, y\n",
    "\n",
    "print([x.shape for x in lm_prior_sample(size=())])\n",
    "print([x.shape for x in lm_prior_sample(size=10)])\n",
    "print([x.shape for x in lm_prior_sample(size=[10, 3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_prior_sample2(size=10):\n",
    "    intercept = stats.norm(loc=0, scale=10.0).rvs(size=size)\n",
    "    beta = stats.multivariate_normal(\n",
    "        mean=np.zeros(n_feature), cov=10.0).rvs(size=size)\n",
    "    sigma = stats.halfnorm(loc=0., scale=1.).rvs(size=size)\n",
    "    y_hat = np.einsum('ij,...j->...i', X, beta) + intercept[..., None]\n",
    "    y = stats.norm(loc=y_hat, scale=sigma[..., None]).rvs()\n",
    "    return intercept, beta, sigma, y\n",
    "\n",
    "print([x.shape for x in lm_prior_sample2(size=())])\n",
    "print([x.shape for x in lm_prior_sample2(size=10)])\n",
    "print([x.shape for x in lm_prior_sample2(size=(10, 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "lognormal0 = tfd.LogNormal(0., 1.)\n",
    "lognormal1 = tfd.TransformedDistribution(tfd.Normal(0., 1.), tfb.Exp())\n",
    "x = lognormal0.sample(100)\n",
    "\n",
    "np.testing.assert_array_equal(lognormal0.log_prob(x), lognormal1.log_prob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfb.MaskedAutoregressiveFlow\n",
    "# tfb.RealNVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X = tf.constant(X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = tfd.JointDistributionSequential([\n",
    "    tfd.Normal(0, 10),\n",
    "    tfd.Sample(tfd.Normal(0, 10), n_feature),\n",
    "    tfd.HalfNormal(1),\n",
    "    lambda sigma, beta, intercept: tfd.Independent(\n",
    "        tfd.Normal(\n",
    "            loc=tf.einsum('ij,...j->...i', X, beta) + intercept[..., None],\n",
    "            scale=sigma[..., None]\n",
    "        ),\n",
    "        reinterpreted_batch_ndims=1,\n",
    "        name='y'\n",
    "    )\n",
    "])\n",
    "\n",
    "print(jd)\n",
    "\n",
    "n_sample = [3, 2]\n",
    "for log_prob_part in jd.log_prob_parts(jd.sample(n_sample)):\n",
    "    assert log_prob_part.shape == n_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorrect if you forgot to wrap tfd.Independent\n",
    "\n",
    "# jd = tfd.JointDistributionSequential([\n",
    "#     tfd.Normal(0, 10),\n",
    "#     tfd.Sample(tfd.Normal(0, 10), n_feature),\n",
    "#     tfd.HalfNormal(1),\n",
    "#     lambda sigma, beta, intercept: tfd.Normal(\n",
    "#             loc=tf.einsum('ij,...j->...i', X, beta) + intercept[..., None],\n",
    "#             scale=sigma[..., None],\n",
    "#             name='y'\n",
    "#     )\n",
    "# ])\n",
    "\n",
    "# jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tfd.JointDistributionSequentialAutoBatched\n",
    "\n",
    "# jd = tfd.JointDistributionSequentialAutoBatched([\n",
    "#     tfd.Normal(0, 10),\n",
    "#     tfd.Sample(tfd.Normal(0, 10), n_feature),\n",
    "#     tfd.HalfNormal(1),\n",
    "#     lambda sigma, beta, intercept: tfd.Normal(\n",
    "#         loc=X @ beta[..., None] + intercept,\n",
    "#         scale=sigma,\n",
    "#         name='y')\n",
    "# ])\n",
    "\n",
    "# jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, value = jd.sample_distributions(3)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd.log_prob_parts(jd.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import numpyro\n",
    "from tensorflow_probability.substrates import jax as tfp_jax\n",
    "\n",
    "tfp_dist = tfp_jax.distributions\n",
    "numpyro_dist = numpyro.distributions\n",
    "\n",
    "init_key = jax.random.PRNGKey(52346)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfp_model():\n",
    "    x = yield tfp_dist.Normal(loc=1.0, scale=2.0, name=\"x\")\n",
    "    z = yield tfp_dist.HalfNormal(scale=1., name=\"z\")\n",
    "    y = yield tfp_dist.Normal(loc=x, scale=z, name=\"y\")\n",
    "    \n",
    "def numpyro_model():\n",
    "    x = numpyro.sample(\"x\", numpyro_dist.Normal(loc=1.0, scale=2.0))\n",
    "    z = numpyro.sample(\"z\", numpyro_dist.HalfNormal(scale=1.0))\n",
    "    y = numpyro.sample(\"y\", numpyro_dist.Normal(loc=x, scale=z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(tfp_model())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(numpyro_model())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_key, sample_key = jax.random.split(init_key, 2)\n",
    "tfp_dist.Normal(0., 1.).sample(seed=sample_key), numpyro_dist.Normal(0., 1.).sample(key=sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key = jax.random.PRNGKey(52346)\n",
    "\n",
    "# Draw samples\n",
    "jd = tfp_dist.JointDistributionCoroutineAutoBatched(tfp_model)\n",
    "tfp_sample = jd.sample(1, seed=sample_key)\n",
    "\n",
    "predictive = numpyro.infer.Predictive(numpyro_model, num_samples=1)\n",
    "numpyro_sample = predictive(sample_key)\n",
    "\n",
    "# Evaluate log prob\n",
    "log_likelihood_tfp = jd.log_prob(tfp_sample)\n",
    "log_likelihood_numpyro = numpyro.infer.util.log_density(\n",
    "    numpyro_model, [], {}, params=tfp_sample._asdict())\n",
    "\n",
    "# Same log prob\n",
    "np.testing.assert_allclose(log_likelihood_tfp, log_likelihood_numpyro[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_tfp, tfp_sample, log_likelihood_numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition z to .01 in TFP\n",
    "jd.sample(z=.01, seed=sample_key)\n",
    "\n",
    "# Condition z to .01 in NumPyro\n",
    "predictive = numpyro.infer.Predictive(\n",
    "    numpyro_model, num_samples=1, params={'z': np.asarray(.01)})\n",
    "predictive(sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditioned z to .01 in TFP and construct conditional distributions\n",
    "dist, value = jd.sample_distributions(z=.01, seed=sample_key)\n",
    "assert dist.y.loc == value.x\n",
    "assert dist.y.scale == value.z\n",
    "\n",
    "# Conditioned z to .01 in NumPyro and construct conditional distributions\n",
    "model = numpyro.handlers.substitute(numpyro_model, data={'z': .01})\n",
    "with numpyro.handlers.seed(rng_seed=sample_key):\n",
    "    # Under the seed context, the default behavior of a NumPyro model is the\n",
    "    # same as in Pyro: drawing prior sample.\n",
    "    model_trace = numpyro.handlers.trace(numpyro_model).get_trace()\n",
    "assert model_trace['y']['fn'].loc == model_trace['x']['value']\n",
    "assert model_trace['y']['fn'].scale == model_trace['z']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpyro_model_with_input(a):\n",
    "    x = numpyro.sample(\"x\", numpyro_dist.Normal(loc=1.0, scale=2.0))\n",
    "    z = numpyro.sample(\"z\", numpyro_dist.HalfNormal(scale=1.0))\n",
    "    y = numpyro.sample(\"y\", numpyro_dist.Normal(loc=x, scale=z))\n",
    "    k = numpyro.sample(\"k\", numpyro_dist.Poisson(rate=y))\n",
    "    return x, z, y, k, z + a\n",
    "\n",
    "with numpyro.handlers.seed(rng_seed=sample_key):\n",
    "    # Under the seed context, the default behavior of a NumPyro model is the\n",
    "    # same as in Pyro: drawing prior sample.\n",
    "    print(numpyro_model_with_input(a=5.))\n",
    "    conditioned_model = numpyro.handlers.condition(numpyro_model_with_input, {'z': .01})\n",
    "    print(conditioned_model(a=5.))\n",
    "    \n",
    "conditioned_model_tfp = jd.experimental_pin(z=.01)\n",
    "conditioned_model_tfp.sample_unpinned(seed=sample_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = numpyro.handlers.substitute(numpyro_model_with_input,\n",
    "                                    data={'z': .01, 'x': 3., 'y': 3.1, 'k': 5})\n",
    "model_trace = numpyro.handlers.trace(model).get_trace(a=5.)\n",
    "\n",
    "log_joint = jax.numpy.array(0.)\n",
    "for site in model_trace.values():\n",
    "    log_prob = site['fn'].log_prob(site['value'])\n",
    "    log_prob = jax.numpy.sum(log_prob)\n",
    "    log_joint = log_joint + log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
